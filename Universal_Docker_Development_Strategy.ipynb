{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3110b93b",
   "metadata": {},
   "source": [
    "# Universal Docker Development Strategy\n",
    "\n",
    "This notebook provides a comprehensive guide to implementing a universal Docker development strategy. The goal is to create a containerized development environment that works consistently across different projects and team members, eliminating \"works on my machine\" issues and streamlining the development process.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll cover the following key areas:\n",
    "1. Basic Docker Environment Setup\n",
    "2. Backend Development Container\n",
    "3. Frontend Development Container\n",
    "4. Database Containers\n",
    "5. Development Tools Container\n",
    "6. VS Code Integration\n",
    "7. Production Optimization\n",
    "8. Automation Scripts\n",
    "\n",
    "Each section will include practical examples and best practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ed02f",
   "metadata": {},
   "source": [
    "# Universal Docker Development Strategy\n",
    "\n",
    "## Containerized Development Environment for Any Project\n",
    "\n",
    "**Goal**: Create a comprehensive Docker-based development strategy that eliminates local dependency conflicts and provides consistent, isolated development environments for all types of projects.\n",
    "\n",
    "### Key Benefits\n",
    "- âœ… **Eliminate \"Works on My Machine\" Issues**: Consistent environments across all development machines\n",
    "- âœ… **Zero Local Dependencies**: No need to install languages, databases, or tools on host machine\n",
    "- âœ… **Team Consistency**: Every developer works in identical environments\n",
    "- âœ… **Easy Onboarding**: New team members get productive immediately\n",
    "- âœ… **Production Parity**: Development closely mirrors production environments\n",
    "- âœ… **Version Control**: Infrastructure as code with versioned configurations\n",
    "\n",
    "### Strategy Overview\n",
    "This notebook provides a complete implementation strategy for containerizing:\n",
    "1. **Backend/API Development** - Multi-language runtime environments\n",
    "2. **Frontend Development** - Modern web development tools and frameworks\n",
    "3. **Database Infrastructure** - Multiple database systems with administration tools\n",
    "4. **Development Tools** - Code quality, testing, and CI/CD utilities\n",
    "5. **IDE Integration** - VS Code dev containers and remote development\n",
    "6. **Production Deployment** - Optimized containers for production use\n",
    "\n",
    "Let's build a universal development environment that works anywhere, anytime!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfd23c",
   "metadata": {},
   "source": [
    "## 1. Docker Environment Setup\n",
    "\n",
    "The foundation of our development strategy is a well-structured Docker environment. We'll create a base `docker-compose.yml` that can be extended for different use cases. Key considerations include:\n",
    "\n",
    "- Network isolation\n",
    "- Volume management for persistence\n",
    "- Environment variable handling\n",
    "- Service dependencies\n",
    "- Health checks\n",
    "\n",
    "Let's start with a basic docker-compose configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87645a9",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  app:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/dev-backend.Dockerfile\n",
    "    volumes:\n",
    "      - .:/app\n",
    "      - node_modules:/app/node_modules\n",
    "    environment:\n",
    "      - NODE_ENV=development\n",
    "    ports:\n",
    "      - \"3000:3000\"\n",
    "    depends_on:\n",
    "      - db\n",
    "      - redis\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 3\n",
    "\n",
    "  db:\n",
    "    image: postgres:14-alpine\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "    environment:\n",
    "      - POSTGRES_USER=dev\n",
    "      - POSTGRES_PASSWORD=dev\n",
    "      - POSTGRES_DB=app_development\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "\n",
    "  redis:\n",
    "    image: redis:alpine\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "\n",
    "networks:\n",
    "  default:\n",
    "    name: app_network\n",
    "\n",
    "volumes:\n",
    "  node_modules:\n",
    "  postgres_data:\n",
    "  redis_data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a78a3",
   "metadata": {},
   "source": [
    "## 2. Backend Development Container\n",
    "\n",
    "Our backend development container needs to provide a complete development environment with all necessary tools and configurations. Key features include:\n",
    "\n",
    "- Latest LTS runtime versions\n",
    "- Development tools and debugging capabilities\n",
    "- Hot reload support\n",
    "- Testing frameworks\n",
    "- Database clients\n",
    "- Development utilities\n",
    "\n",
    "Here's our backend development Dockerfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3054bc89",
   "metadata": {
    "vscode": {
     "languageId": "dockerfile"
    }
   },
   "outputs": [],
   "source": [
    "# docker/dev-backend.Dockerfile\n",
    "FROM node:20-bullseye\n",
    "\n",
    "# Install common development tools\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    git \\\n",
    "    curl \\\n",
    "    wget \\\n",
    "    vim \\\n",
    "    postgresql-client \\\n",
    "    python3 \\\n",
    "    python3-pip \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install global Node.js development tools\n",
    "RUN npm install -g nodemon typescript ts-node\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install project dependencies\n",
    "COPY package*.json ./\n",
    "RUN npm install\n",
    "\n",
    "# Copy source code\n",
    "COPY . .\n",
    "\n",
    "# Set development environment\n",
    "ENV NODE_ENV=development\n",
    "\n",
    "# Add debugging port\n",
    "EXPOSE 9229\n",
    "\n",
    "# Start development server with hot reload\n",
    "CMD [\"npm\", \"run\", \"dev\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ead756",
   "metadata": {},
   "source": [
    "## 3. Frontend Development Container\n",
    "\n",
    "The frontend development container focuses on providing a modern web development environment with:\n",
    "\n",
    "- Node.js and npm/yarn\n",
    "- Build tools and bundlers\n",
    "- Hot module replacement\n",
    "- Testing frameworks\n",
    "- Code quality tools\n",
    "- Browser testing capabilities\n",
    "\n",
    "Here's our frontend development Dockerfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32f677",
   "metadata": {
    "vscode": {
     "languageId": "dockerfile"
    }
   },
   "outputs": [],
   "source": [
    "# docker/dev-frontend.Dockerfile\n",
    "FROM node:20-bullseye\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    git \\\n",
    "    curl \\\n",
    "    chromium \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install global development tools\n",
    "RUN npm install -g \\\n",
    "    @vue/cli \\\n",
    "    create-react-app \\\n",
    "    @angular/cli \\\n",
    "    vite \\\n",
    "    playwright\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install project dependencies\n",
    "COPY package*.json ./\n",
    "RUN npm install\n",
    "\n",
    "# Copy source code\n",
    "COPY . .\n",
    "\n",
    "# Set development environment\n",
    "ENV NODE_ENV=development\n",
    "\n",
    "# Expose development server port\n",
    "EXPOSE 3000\n",
    "\n",
    "# Start development server with hot reload\n",
    "CMD [\"npm\", \"run\", \"dev\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532d3dab",
   "metadata": {},
   "source": [
    "## 4. Database Container Configuration\n",
    "\n",
    "Our database setup includes multiple databases for different purposes:\n",
    "\n",
    "- PostgreSQL for primary data storage\n",
    "- Redis for caching and sessions\n",
    "- MongoDB for document storage\n",
    "\n",
    "We'll configure them with:\n",
    "- Data persistence\n",
    "- Initialization scripts\n",
    "- Backup utilities\n",
    "- Admin tools\n",
    "\n",
    "Here's our database configuration in docker-compose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953075c",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "# Extended database services in docker-compose.yml\n",
    "services:\n",
    "  postgres:\n",
    "    image: postgres:14-alpine\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "      - ./init-scripts:/docker-entrypoint-initdb.d\n",
    "    environment:\n",
    "      POSTGRES_USER: dev\n",
    "      POSTGRES_PASSWORD: dev\n",
    "      POSTGRES_DB: app_dev\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U dev\"]\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  redis:\n",
    "    image: redis:alpine\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    command: redis-server --appendonly yes\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"redis-cli\", \"ping\"]\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  mongodb:\n",
    "    image: mongo:latest\n",
    "    volumes:\n",
    "      - mongo_data:/data/db\n",
    "      - ./init-scripts:/docker-entrypoint-initdb.d\n",
    "    environment:\n",
    "      MONGO_INITDB_ROOT_USERNAME: dev\n",
    "      MONGO_INITDB_ROOT_PASSWORD: dev\n",
    "      MONGO_INITDB_DATABASE: app_dev\n",
    "    ports:\n",
    "      - \"27017:27017\"\n",
    "    healthcheck:\n",
    "      test: echo 'db.runCommand(\"ping\").ok' | mongosh localhost:27017/test --quiet\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  pgadmin:\n",
    "    image: dpage/pgadmin4\n",
    "    environment:\n",
    "      PGADMIN_DEFAULT_EMAIL: dev@example.com\n",
    "      PGADMIN_DEFAULT_PASSWORD: dev\n",
    "    ports:\n",
    "      - \"5050:80\"\n",
    "    depends_on:\n",
    "      - postgres\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "  redis_data:\n",
    "  mongo_data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ffabf",
   "metadata": {},
   "source": [
    "## 5. Development Tools Container\n",
    "\n",
    "Our development tools container provides a comprehensive set of utilities for:\n",
    "\n",
    "- Code quality assurance\n",
    "- Testing and debugging\n",
    "- Documentation generation\n",
    "- Security scanning\n",
    "- API development\n",
    "\n",
    "Here's our development tools Dockerfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf68a7",
   "metadata": {
    "vscode": {
     "languageId": "dockerfile"
    }
   },
   "outputs": [],
   "source": [
    "# docker/dev-tools.Dockerfile\n",
    "FROM ubuntu:22.04\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "    git \\\n",
    "    curl \\\n",
    "    wget \\\n",
    "    python3 \\\n",
    "    python3-pip \\\n",
    "    nodejs \\\n",
    "    npm \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Python development tools\n",
    "RUN pip3 install \\\n",
    "    black \\\n",
    "    pylint \\\n",
    "    pytest \\\n",
    "    pytest-cov \\\n",
    "    bandit \\\n",
    "    sphinx \\\n",
    "    mkdocs \\\n",
    "    mkdocs-material\n",
    "\n",
    "# Install Node.js development tools\n",
    "RUN npm install -g \\\n",
    "    eslint \\\n",
    "    prettier \\\n",
    "    jest \\\n",
    "    typescript \\\n",
    "    typedoc \\\n",
    "    swagger-cli \\\n",
    "    @stoplight/spectral-cli\n",
    "\n",
    "# Install security tools\n",
    "RUN pip3 install \\\n",
    "    safety \\\n",
    "    semgrep \\\n",
    "    detect-secrets\n",
    "\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Mount the project directory when running\n",
    "VOLUME [\"/workspace\"]\n",
    "\n",
    "# Default command to show available tools\n",
    "CMD [\"bash\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba277dd",
   "metadata": {},
   "source": [
    "## 6. VS Code Integration\n",
    "\n",
    "VS Code provides excellent support for Docker-based development through its Remote Development extension pack. We'll configure:\n",
    "\n",
    "- Development containers\n",
    "- Extensions for our stack\n",
    "- Debugging configurations\n",
    "- Task runners\n",
    "- Source control integration\n",
    "\n",
    "Here's our VS Code development container configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54684933",
   "metadata": {
    "vscode": {
     "languageId": "json"
    }
   },
   "outputs": [],
   "source": [
    "# .devcontainer/devcontainer.json\n",
    "{\n",
    "  \"name\": \"Development Environment\",\n",
    "  \"dockerComposeFile\": \"../docker-compose.yml\",\n",
    "  \"service\": \"app\",\n",
    "  \"workspaceFolder\": \"/app\",\n",
    "  \"customizations\": {\n",
    "    \"vscode\": {\n",
    "      \"extensions\": [\n",
    "        \"dbaeumer.vscode-eslint\",\n",
    "        \"esbenp.prettier-vscode\",\n",
    "        \"ms-python.python\",\n",
    "        \"ms-azuretools.vscode-docker\",\n",
    "        \"eamodio.gitlens\",\n",
    "        \"GitHub.copilot\",\n",
    "        \"ms-vscode.vscode-typescript-tslint-plugin\",\n",
    "        \"redhat.vscode-yaml\",\n",
    "        \"mikestead.dotenv\"\n",
    "      ],\n",
    "      \"settings\": {\n",
    "        \"editor.formatOnSave\": true,\n",
    "        \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n",
    "        \"editor.codeActionsOnSave\": {\n",
    "          \"source.fixAll.eslint\": true\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"forwardPorts\": [3000, 5432, 6379, 27017],\n",
    "  \"postCreateCommand\": \"npm install\",\n",
    "  \"remoteUser\": \"node\",\n",
    "  \"features\": {\n",
    "    \"docker-in-docker\": \"latest\",\n",
    "    \"git\": \"latest\",\n",
    "    \"github-cli\": \"latest\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5b601d",
   "metadata": {},
   "source": [
    "## 7. Production Optimization\n",
    "\n",
    "For production deployments, we need to optimize our containers for:\n",
    "\n",
    "- Minimal image size\n",
    "- Security best practices\n",
    "- Resource efficiency\n",
    "- Monitoring capabilities\n",
    "- Scalability\n",
    "\n",
    "Here's an example of a production-optimized Dockerfile using multi-stage builds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6805b17",
   "metadata": {
    "vscode": {
     "languageId": "dockerfile"
    }
   },
   "outputs": [],
   "source": [
    "# Dockerfile.production\n",
    "# Build stage\n",
    "FROM node:20-alpine as builder\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy package files\n",
    "COPY package*.json ./\n",
    "RUN npm ci\n",
    "\n",
    "# Copy source code\n",
    "COPY . .\n",
    "\n",
    "# Build application\n",
    "RUN npm run build\n",
    "\n",
    "# Production stage\n",
    "FROM node:20-alpine\n",
    "\n",
    "# Create non-root user\n",
    "RUN addgroup -S appgroup && adduser -S appuser -G appgroup\n",
    "\n",
    "# Install production dependencies\n",
    "WORKDIR /app\n",
    "COPY package*.json ./\n",
    "RUN npm ci --production\n",
    "\n",
    "# Copy built assets from builder\n",
    "COPY --from=builder /app/dist ./dist\n",
    "\n",
    "# Set user\n",
    "USER appuser\n",
    "\n",
    "# Configure health check\n",
    "HEALTHCHECK --interval=30s --timeout=3s \\\n",
    "  CMD wget --quiet --tries=1 --spider http://localhost:3000/health || exit 1\n",
    "\n",
    "# Set environment\n",
    "ENV NODE_ENV=production\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 3000\n",
    "\n",
    "# Start application\n",
    "CMD [\"node\", \"dist/server.js\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50efe49c",
   "metadata": {},
   "source": [
    "## 8. Automation Scripts\n",
    "\n",
    "To streamline development workflows, we'll create automation scripts for common tasks:\n",
    "\n",
    "- Environment setup and teardown\n",
    "- Testing and linting\n",
    "- Building and deployment\n",
    "- Database operations\n",
    "- Log management\n",
    "\n",
    "Here's our Makefile for common development commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff35de",
   "metadata": {
    "vscode": {
     "languageId": "makefile"
    }
   },
   "outputs": [],
   "source": [
    "# Makefile\n",
    ".PHONY: dev-start dev-stop dev-reset test lint build deploy logs db-migrate db-seed\n",
    "\n",
    "# Development environment\n",
    "dev-start:\n",
    "\tdocker-compose up -d\n",
    "\n",
    "dev-stop:\n",
    "\tdocker-compose down\n",
    "\n",
    "dev-reset:\n",
    "\tdocker-compose down -v\n",
    "\tdocker-compose up -d\n",
    "\n",
    "# Testing and quality\n",
    "test:\n",
    "\tdocker-compose run --rm app npm test\n",
    "\n",
    "lint:\n",
    "\tdocker-compose run --rm app npm run lint\n",
    "\n",
    "# Build and deployment\n",
    "build:\n",
    "\tdocker build -f Dockerfile.production -t app:latest .\n",
    "\n",
    "deploy:\n",
    "\tdocker-compose -f docker-compose.prod.yml up -d\n",
    "\n",
    "# Database operations\n",
    "db-migrate:\n",
    "\tdocker-compose run --rm app npm run migrate\n",
    "\n",
    "db-seed:\n",
    "\tdocker-compose run --rm app npm run seed\n",
    "\n",
    "# Logs and monitoring\n",
    "logs:\n",
    "\tdocker-compose logs -f\n",
    "\n",
    "# Clean up\n",
    "clean:\n",
    "\tdocker-compose down -v\n",
    "\tdocker system prune -f\n",
    "\n",
    "# Help\n",
    "help:\n",
    "\t@echo \"Available commands:\"\n",
    "\t@echo \"  make dev-start    - Start development environment\"\n",
    "\t@echo \"  make dev-stop     - Stop development environment\"\n",
    "\t@echo \"  make dev-reset    - Reset development environment\"\n",
    "\t@echo \"  make test         - Run tests\"\n",
    "\t@echo \"  make lint         - Run linters\"\n",
    "\t@echo \"  make build        - Build production image\"\n",
    "\t@echo \"  make deploy       - Deploy to production\"\n",
    "\t@echo \"  make db-migrate   - Run database migrations\"\n",
    "\t@echo \"  make db-seed      - Seed database with test data\"\n",
    "\t@echo \"  make logs         - View container logs\"\n",
    "\t@echo \"  make clean        - Clean up containers and volumes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b378352",
   "metadata": {},
   "source": [
    "## Conclusion and Best Practices\n",
    "\n",
    "This Docker development strategy provides a robust foundation for modern application development:\n",
    "\n",
    "1. **Consistency**: Developers work in identical environments, eliminating \"works on my machine\" issues\n",
    "2. **Modularity**: Each service is containerized and can be developed/tested independently\n",
    "3. **Scalability**: Easy transition from development to production with optimized containers\n",
    "4. **Maintainability**: Automation scripts and clear documentation make the system easy to maintain\n",
    "5. **Security**: Production-ready configurations with security best practices built-in\n",
    "\n",
    "Remember to:\n",
    "- Keep containers focused and minimal\n",
    "- Use proper versioning for images\n",
    "- Implement health checks\n",
    "- Monitor resource usage\n",
    "- Regularly update base images\n",
    "- Document all customizations\n",
    "- Follow security best practices\n",
    "\n",
    "By following this strategy, teams can achieve a more efficient and reliable development workflow while maintaining high standards for code quality and security."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66f8e0a",
   "metadata": {},
   "source": [
    "## 1. Docker Development Environment Setup\n",
    "\n",
    "### Initial Project Structure\n",
    "\n",
    "First, let's create the foundational directory structure for our Docker development environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f17136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Universal Docker Development Environment Setup\n",
    "Creates the foundational directory structure and configuration files\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def create_docker_structure():\n",
    "    \"\"\"Create the complete Docker development structure\"\"\"\n",
    "\n",
    "    # Define the directory structure\n",
    "    dirs = [\n",
    "        'docker',\n",
    "        'docker/development',\n",
    "        'docker/production',\n",
    "        'docker/tools',\n",
    "        '.devcontainer',\n",
    "        'scripts',\n",
    "        'config/dev',\n",
    "        'config/staging',\n",
    "        'config/production',\n",
    "        'data/dev',\n",
    "        'logs/dev'\n",
    "    ]\n",
    "\n",
    "    print(\"ðŸ³ Creating Universal Docker Development Structure...\")\n",
    "\n",
    "    # Create directories\n",
    "    for dir_path in dirs:\n",
    "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"âœ… Created: {dir_path}/\")\n",
    "\n",
    "    print(f\"\\nðŸŽ‰ Docker development structure created successfully!\")\n",
    "    print(\"ðŸ“ Project now ready for containerized development\")\n",
    "\n",
    "    return dirs\n",
    "\n",
    "# Execute setup\n",
    "created_dirs = create_docker_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base docker-compose.yml configuration\n",
    "docker_compose_content = \"\"\"\n",
    "version: '3.8'\n",
    "\n",
    "networks:\n",
    "  dev-network:\n",
    "    driver: bridge\n",
    "    ipam:\n",
    "      config:\n",
    "        - subnet: 172.20.0.0/16\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "  mysql_data:\n",
    "  redis_data:\n",
    "  mongodb_data:\n",
    "  minio_data:\n",
    "  node_modules:\n",
    "  python_venv:\n",
    "\n",
    "services:\n",
    "  # Backend development container\n",
    "  backend-dev:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/backend.Dockerfile\n",
    "    container_name: universal-backend-dev\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - python_venv:/opt/venv\n",
    "      - node_modules:/workspace/node_modules\n",
    "    ports:\n",
    "      - \"3000:3000\"   # Node.js/Express\n",
    "      - \"8000:8000\"   # Python/FastAPI\n",
    "      - \"8080:8080\"   # Java/Spring Boot\n",
    "      - \"9000:9000\"   # Go applications\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - NODE_ENV=development\n",
    "      - PYTHON_ENV=development\n",
    "      - DATABASE_URL=postgresql://devuser:devpass@postgres-dev:5432/devdb\n",
    "      - REDIS_URL=redis://redis-dev:6379\n",
    "    depends_on:\n",
    "      - postgres-dev\n",
    "      - redis-dev\n",
    "    command: tail -f /dev/null\n",
    "\n",
    "  # Frontend development container\n",
    "  frontend-dev:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/frontend.Dockerfile\n",
    "    container_name: universal-frontend-dev\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - node_modules:/workspace/node_modules\n",
    "    ports:\n",
    "      - \"3001:3000\"   # React/Vue/Angular dev server\n",
    "      - \"5173:5173\"   # Vite dev server\n",
    "      - \"4200:4200\"   # Angular CLI\n",
    "      - \"8081:8080\"   # Vue CLI\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - NODE_ENV=development\n",
    "      - CHOKIDAR_USEPOLLING=true\n",
    "      - WATCHPACK_POLLING=true\n",
    "    command: tail -f /dev/null\n",
    "\n",
    "  # PostgreSQL development database\n",
    "  postgres-dev:\n",
    "    image: postgres:15-alpine\n",
    "    container_name: universal-postgres-dev\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "      - ./docker/development/postgres-init.sql:/docker-entrypoint-initdb.d/init.sql\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - POSTGRES_DB=devdb\n",
    "      - POSTGRES_USER=devuser\n",
    "      - POSTGRES_PASSWORD=devpass\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U devuser -d devdb\"]\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  # Redis cache and sessions\n",
    "  redis-dev:\n",
    "    image: redis:7-alpine\n",
    "    container_name: universal-redis-dev\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    command: redis-server --appendonly yes\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"redis-cli\", \"ping\"]\n",
    "      interval: 10s\n",
    "      timeout: 3s\n",
    "      retries: 5\n",
    "\n",
    "  # Development tools container\n",
    "  dev-tools:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/tools/dev-tools.Dockerfile\n",
    "    container_name: universal-dev-tools\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "    networks:\n",
    "      - dev-network\n",
    "    command: tail -f /dev/null\n",
    "\"\"\"\n",
    "\n",
    "# Write docker-compose.yml\n",
    "with open('docker-compose.yml', 'w') as f:\n",
    "    f.write(docker_compose_content.strip())\n",
    "\n",
    "print(\"âœ… Created: docker-compose.yml\")\n",
    "print(\"ðŸ”§ Base development services configured:\")\n",
    "print(\"   - Backend development container (multi-language)\")\n",
    "print(\"   - Frontend development container\")\n",
    "print(\"   - PostgreSQL database\")\n",
    "print(\"   - Redis cache\")\n",
    "print(\"   - Development tools container\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20bbef",
   "metadata": {},
   "source": [
    "## 2. Backend Development Container Creation\n",
    "\n",
    "### Multi-Language Backend Development Environment\n",
    "\n",
    "Creating a comprehensive backend development container that supports multiple programming languages and frameworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc7c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Backend Development Dockerfile\n",
    "backend_dockerfile = \"\"\"\n",
    "FROM ubuntu:22.04\n",
    "\n",
    "# Avoid interactive prompts during installation\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "ENV TZ=UTC\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    curl \\\\\n",
    "    wget \\\\\n",
    "    git \\\\\n",
    "    vim \\\\\n",
    "    build-essential \\\\\n",
    "    software-properties-common \\\\\n",
    "    ca-certificates \\\\\n",
    "    gnupg \\\\\n",
    "    lsb-release \\\\\n",
    "    unzip \\\\\n",
    "    jq \\\\\n",
    "    htop \\\\\n",
    "    tree \\\\\n",
    "    postgresql-client \\\\\n",
    "    mysql-client \\\\\n",
    "    redis-tools \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Node.js (LTS)\n",
    "RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - \\\\\n",
    "    && apt-get install -y nodejs\n",
    "\n",
    "# Install Python 3.11\n",
    "RUN add-apt-repository ppa:deadsnakes/ppa \\\\\n",
    "    && apt-get update \\\\\n",
    "    && apt-get install -y python3.11 python3.11-dev python3.11-venv python3-pip \\\\\n",
    "    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1 \\\\\n",
    "    && update-alternatives --install /usr/bin/python python /usr/bin/python3.11 1\n",
    "\n",
    "# Install Go\n",
    "RUN wget https://go.dev/dl/go1.21.0.linux-amd64.tar.gz \\\\\n",
    "    && tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz \\\\\n",
    "    && rm go1.21.0.linux-amd64.tar.gz\n",
    "ENV PATH=$PATH:/usr/local/go/bin\n",
    "\n",
    "# Install Java (OpenJDK 17)\n",
    "RUN apt-get update && apt-get install -y openjdk-17-jdk \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64\n",
    "\n",
    "# Install Rust\n",
    "RUN curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
    "ENV PATH=\"/root/.cargo/bin:${PATH}\"\n",
    "\n",
    "# Install development tools\n",
    "RUN npm install -g \\\\\n",
    "    typescript \\\\\n",
    "    ts-node \\\\\n",
    "    nodemon \\\\\n",
    "    @nestjs/cli \\\\\n",
    "    @angular/cli \\\\\n",
    "    vue-cli \\\\\n",
    "    create-react-app \\\\\n",
    "    vite \\\\\n",
    "    eslint \\\\\n",
    "    prettier \\\\\n",
    "    pm2\n",
    "\n",
    "# Install Python development tools\n",
    "RUN python3 -m pip install --upgrade pip \\\\\n",
    "    && pip install \\\\\n",
    "    poetry \\\\\n",
    "    pipenv \\\\\n",
    "    fastapi \\\\\n",
    "    uvicorn \\\\\n",
    "    django \\\\\n",
    "    flask \\\\\n",
    "    sqlalchemy \\\\\n",
    "    alembic \\\\\n",
    "    pytest \\\\\n",
    "    pytest-cov \\\\\n",
    "    black \\\\\n",
    "    flake8 \\\\\n",
    "    mypy \\\\\n",
    "    bandit \\\\\n",
    "    pre-commit \\\\\n",
    "    jupyter \\\\\n",
    "    notebook\n",
    "\n",
    "# Install Go development tools\n",
    "RUN go install golang.org/x/tools/gopls@latest \\\\\n",
    "    && go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest \\\\\n",
    "    && go install github.com/gin-gonic/gin@latest\n",
    "\n",
    "# Install Maven for Java projects\n",
    "RUN wget https://downloads.apache.org/maven/maven-3/3.9.4/binaries/apache-maven-3.9.4-bin.tar.gz \\\\\n",
    "    && tar xzf apache-maven-3.9.4-bin.tar.gz -C /opt \\\\\n",
    "    && ln -s /opt/apache-maven-3.9.4 /opt/maven \\\\\n",
    "    && rm apache-maven-3.9.4-bin.tar.gz\n",
    "ENV MAVEN_HOME=/opt/maven\n",
    "ENV PATH=$PATH:$MAVEN_HOME/bin\n",
    "\n",
    "# Install database migration tools\n",
    "RUN curl -L https://github.com/golang-migrate/migrate/releases/download/v4.16.2/migrate.linux-amd64.tar.gz | tar xvz \\\\\n",
    "    && mv migrate /usr/local/bin/\n",
    "\n",
    "# Create development user\n",
    "RUN useradd -m -s /bin/bash developer \\\\\n",
    "    && usermod -aG sudo developer \\\\\n",
    "    && echo 'developer ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Create virtual environment for Python\n",
    "RUN python3 -m venv /opt/venv\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\\\n",
    "    CMD curl -f http://localhost:3000/health || exit 1\n",
    "\n",
    "# Switch to developer user\n",
    "USER developer\n",
    "\n",
    "# Default command\n",
    "CMD [\"bash\"]\n",
    "\"\"\"\n",
    "\n",
    "# Write Backend Dockerfile\n",
    "os.makedirs('docker/development', exist_ok=True)\n",
    "with open('docker/development/backend.Dockerfile', 'w') as f:\n",
    "    f.write(backend_dockerfile.strip())\n",
    "\n",
    "print(\"âœ… Created: docker/development/backend.Dockerfile\")\n",
    "print(\"ðŸš€ Backend development container includes:\")\n",
    "print(\"   - Node.js 18 LTS with npm/yarn\")\n",
    "print(\"   - Python 3.11 with Poetry, FastAPI, Django\")\n",
    "print(\"   - Go 1.21 with common tools\")\n",
    "print(\"   - Java 17 OpenJDK with Maven\")\n",
    "print(\"   - Rust with Cargo\")\n",
    "print(\"   - Database clients (PostgreSQL, MySQL, Redis)\")\n",
    "print(\"   - Development tools and linters\")\n",
    "print(\"   - Health checks and debugging utilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82b28f",
   "metadata": {},
   "source": [
    "## 3. Frontend Development Container Configuration\n",
    "\n",
    "### Modern Frontend Development Environment\n",
    "\n",
    "Creating an optimized frontend development container with hot module replacement and modern build tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e23032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Frontend Development Dockerfile\n",
    "frontend_dockerfile = \"\"\"\n",
    "FROM node:18-alpine\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apk add --no-cache \\\\\n",
    "    git \\\\\n",
    "    curl \\\\\n",
    "    wget \\\\\n",
    "    bash \\\\\n",
    "    vim \\\\\n",
    "    python3 \\\\\n",
    "    make \\\\\n",
    "    g++ \\\\\n",
    "    cairo-dev \\\\\n",
    "    jpeg-dev \\\\\n",
    "    pango-dev \\\\\n",
    "    musl-dev \\\\\n",
    "    giflib-dev \\\\\n",
    "    pixman-dev \\\\\n",
    "    pangomm-dev \\\\\n",
    "    libjpeg-turbo-dev \\\\\n",
    "    freetype-dev\n",
    "\n",
    "# Install global npm packages\n",
    "RUN npm install -g \\\\\n",
    "    @angular/cli \\\\\n",
    "    @vue/cli \\\\\n",
    "    create-react-app \\\\\n",
    "    create-next-app \\\\\n",
    "    vite \\\\\n",
    "    webpack \\\\\n",
    "    webpack-cli \\\\\n",
    "    parcel \\\\\n",
    "    typescript \\\\\n",
    "    ts-node \\\\\n",
    "    eslint \\\\\n",
    "    prettier \\\\\n",
    "    sass \\\\\n",
    "    less \\\\\n",
    "    stylus \\\\\n",
    "    postcss \\\\\n",
    "    postcss-cli \\\\\n",
    "    @storybook/cli \\\\\n",
    "    serve \\\\\n",
    "    http-server \\\\\n",
    "    live-server \\\\\n",
    "    pm2 \\\\\n",
    "    concurrently \\\\\n",
    "    cross-env \\\\\n",
    "    rimraf \\\\\n",
    "    husky \\\\\n",
    "    lint-staged\n",
    "\n",
    "# Install Yarn and pnpm\n",
    "RUN npm install -g yarn pnpm\n",
    "\n",
    "# Install browser testing tools\n",
    "RUN npm install -g \\\\\n",
    "    playwright \\\\\n",
    "    cypress \\\\\n",
    "    @playwright/test \\\\\n",
    "    puppeteer \\\\\n",
    "    jest \\\\\n",
    "    @testing-library/jest-dom\n",
    "\n",
    "# Install build and optimization tools\n",
    "RUN npm install -g \\\\\n",
    "    webpack-bundle-analyzer \\\\\n",
    "    bundlesize \\\\\n",
    "    lighthouse \\\\\n",
    "    web-vitals \\\\\n",
    "    @web/dev-server \\\\\n",
    "    esbuild \\\\\n",
    "    rollup \\\\\n",
    "    turbo\n",
    "\n",
    "# Create development user\n",
    "RUN addgroup -g 1000 developer \\\\\n",
    "    && adduser -D -s /bin/bash -u 1000 -G developer developer \\\\\n",
    "    && echo 'developer ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\n",
    "\n",
    "# Install additional CSS frameworks and tools\n",
    "RUN npm install -g \\\\\n",
    "    tailwindcss \\\\\n",
    "    @tailwindcss/cli \\\\\n",
    "    bootstrap \\\\\n",
    "    bulma \\\\\n",
    "    foundation-cli \\\\\n",
    "    @emotion/css \\\\\n",
    "    styled-components\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Environment variables for development\n",
    "ENV NODE_ENV=development\n",
    "ENV CHOKIDAR_USEPOLLING=true\n",
    "ENV WATCHPACK_POLLING=true\n",
    "ENV FAST_REFRESH=true\n",
    "\n",
    "# Expose common development ports\n",
    "EXPOSE 3000 3001 4200 5173 8080 8081 9000 9001\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \\\\\n",
    "    CMD curl -f http://localhost:3000 || curl -f http://localhost:5173 || exit 1\n",
    "\n",
    "# Switch to developer user\n",
    "USER developer\n",
    "\n",
    "# Default command\n",
    "CMD [\"bash\"]\n",
    "\"\"\"\n",
    "\n",
    "# Write Frontend Dockerfile\n",
    "with open('docker/development/frontend.Dockerfile', 'w') as f:\n",
    "    f.write(frontend_dockerfile.strip())\n",
    "\n",
    "print(\"âœ… Created: docker/development/frontend.Dockerfile\")\n",
    "print(\"ðŸŽ¨ Frontend development container includes:\")\n",
    "print(\"   - Node.js 18 Alpine (optimized for frontend)\")\n",
    "print(\"   - React, Vue, Angular CLIs\")\n",
    "print(\"   - Modern build tools (Vite, Webpack, Parcel)\")\n",
    "print(\"   - CSS preprocessors (Sass, Less, PostCSS)\")\n",
    "print(\"   - Testing frameworks (Jest, Playwright, Cypress)\")\n",
    "print(\"   - Package managers (npm, yarn, pnpm)\")\n",
    "print(\"   - Hot module replacement support\")\n",
    "print(\"   - Browser testing and debugging tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9f653",
   "metadata": {},
   "source": [
    "## 4. Database and Infrastructure Container Orchestration\n",
    "\n",
    "### Complete Database Development Stack\n",
    "\n",
    "Setting up a comprehensive database and infrastructure environment with persistent volumes and administration tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f084e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extended database infrastructure configuration\n",
    "database_compose = \"\"\"\n",
    "  # MySQL/MariaDB development database\n",
    "  mysql-dev:\n",
    "    image: mysql:8.0\n",
    "    container_name: universal-mysql-dev\n",
    "    volumes:\n",
    "      - mysql_data:/var/lib/mysql\n",
    "      - ./docker/development/mysql-init.sql:/docker-entrypoint-initdb.d/init.sql\n",
    "    ports:\n",
    "      - \"3306:3306\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - MYSQL_ROOT_PASSWORD=rootpass\n",
    "      - MYSQL_DATABASE=devdb\n",
    "      - MYSQL_USER=devuser\n",
    "      - MYSQL_PASSWORD=devpass\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"]\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  # MongoDB development database\n",
    "  mongodb-dev:\n",
    "    image: mongo:6.0\n",
    "    container_name: universal-mongodb-dev\n",
    "    volumes:\n",
    "      - mongodb_data:/data/db\n",
    "      - ./docker/development/mongo-init.js:/docker-entrypoint-initdb.d/init.js\n",
    "    ports:\n",
    "      - \"27017:27017\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - MONGO_INITDB_ROOT_USERNAME=admin\n",
    "      - MONGO_INITDB_ROOT_PASSWORD=adminpass\n",
    "      - MONGO_INITDB_DATABASE=devdb\n",
    "    healthcheck:\n",
    "      test: echo 'db.runCommand(\"ping\").ok' | mongosh localhost:27017/test --quiet\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  # MinIO S3-compatible object storage\n",
    "  minio-dev:\n",
    "    image: minio/minio:latest\n",
    "    container_name: universal-minio-dev\n",
    "    volumes:\n",
    "      - minio_data:/data\n",
    "    ports:\n",
    "      - \"9000:9000\"\n",
    "      - \"9001:9001\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - MINIO_ROOT_USER=minioadmin\n",
    "      - MINIO_ROOT_PASSWORD=minioadmin123\n",
    "    command: server /data --console-address \":9001\"\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"]\n",
    "      interval: 30s\n",
    "      timeout: 20s\n",
    "      retries: 3\n",
    "\n",
    "  # Elasticsearch for search capabilities\n",
    "  elasticsearch-dev:\n",
    "    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0\n",
    "    container_name: universal-elasticsearch-dev\n",
    "    volumes:\n",
    "      - elasticsearch_data:/usr/share/elasticsearch/data\n",
    "    ports:\n",
    "      - \"9200:9200\"\n",
    "      - \"9300:9300\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - discovery.type=single-node\n",
    "      - xpack.security.enabled=false\n",
    "      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"curl -f http://localhost:9200/_cluster/health || exit 1\"]\n",
    "      interval: 30s\n",
    "      timeout: 10s\n",
    "      retries: 5\n",
    "\n",
    "  # RabbitMQ message broker\n",
    "  rabbitmq-dev:\n",
    "    image: rabbitmq:3.11-management-alpine\n",
    "    container_name: universal-rabbitmq-dev\n",
    "    volumes:\n",
    "      - rabbitmq_data:/var/lib/rabbitmq\n",
    "    ports:\n",
    "      - \"5672:5672\"\n",
    "      - \"15672:15672\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - RABBITMQ_DEFAULT_USER=admin\n",
    "      - RABBITMQ_DEFAULT_PASS=adminpass\n",
    "    healthcheck:\n",
    "      test: rabbitmq-diagnostics -q ping\n",
    "      interval: 30s\n",
    "      timeout: 30s\n",
    "      retries: 3\n",
    "\n",
    "  # Database administration tools\n",
    "  pgadmin:\n",
    "    image: dpage/pgadmin4:7\n",
    "    container_name: universal-pgadmin\n",
    "    volumes:\n",
    "      - pgadmin_data:/var/lib/pgadmin\n",
    "    ports:\n",
    "      - \"5050:80\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - PGADMIN_DEFAULT_EMAIL=admin@example.com\n",
    "      - PGADMIN_DEFAULT_PASSWORD=adminpass\n",
    "    depends_on:\n",
    "      - postgres-dev\n",
    "\n",
    "  phpmyadmin:\n",
    "    image: phpmyadmin/phpmyadmin:5\n",
    "    container_name: universal-phpmyadmin\n",
    "    ports:\n",
    "      - \"8082:80\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - PMA_HOST=mysql-dev\n",
    "      - PMA_USER=devuser\n",
    "      - PMA_PASSWORD=devpass\n",
    "    depends_on:\n",
    "      - mysql-dev\n",
    "\n",
    "  mongo-express:\n",
    "    image: mongo-express:1.0.0-alpha\n",
    "    container_name: universal-mongo-express\n",
    "    ports:\n",
    "      - \"8083:8081\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - ME_CONFIG_MONGODB_ADMINUSERNAME=admin\n",
    "      - ME_CONFIG_MONGODB_ADMINPASSWORD=adminpass\n",
    "      - ME_CONFIG_MONGODB_SERVER=mongodb-dev\n",
    "    depends_on:\n",
    "      - mongodb-dev\n",
    "\"\"\"\n",
    "\n",
    "# Add additional volumes\n",
    "additional_volumes = \"\"\"\n",
    "  elasticsearch_data:\n",
    "  rabbitmq_data:\n",
    "  pgadmin_data:\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… Extended database infrastructure configuration created\")\n",
    "print(\"ðŸ—„ï¸ Database stack includes:\")\n",
    "print(\"   - PostgreSQL 15 with pgAdmin\")\n",
    "print(\"   - MySQL 8.0 with phpMyAdmin\")\n",
    "print(\"   - MongoDB 6.0 with Mongo Express\")\n",
    "print(\"   - Redis 7 for caching\")\n",
    "print(\"   - Elasticsearch 8.8 for search\")\n",
    "print(\"   - RabbitMQ 3.11 with management UI\")\n",
    "print(\"   - MinIO for S3-compatible storage\")\n",
    "print(\"   - All with persistent volumes and health checks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1282dbd",
   "metadata": {},
   "source": [
    "## 5. Development Tools Container Implementation\n",
    "\n",
    "### Code Quality and CI/CD Tools Environment\n",
    "\n",
    "Creating a comprehensive development tools container with linters, formatters, security scanners, and testing frameworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Development Tools Dockerfile\n",
    "devtools_dockerfile = \"\"\"\n",
    "FROM ubuntu:22.04\n",
    "\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# Install system dependencies\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    curl \\\\\n",
    "    wget \\\\\n",
    "    git \\\\\n",
    "    vim \\\\\n",
    "    jq \\\\\n",
    "    unzip \\\\\n",
    "    python3 \\\\\n",
    "    python3-pip \\\\\n",
    "    nodejs \\\\\n",
    "    npm \\\\\n",
    "    openjdk-17-jdk \\\\\n",
    "    maven \\\\\n",
    "    build-essential \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install Go\n",
    "RUN wget https://go.dev/dl/go1.21.0.linux-amd64.tar.gz \\\\\n",
    "    && tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz \\\\\n",
    "    && rm go1.21.0.linux-amd64.tar.gz\n",
    "ENV PATH=$PATH:/usr/local/go/bin\n",
    "\n",
    "# Install Docker CLI\n",
    "RUN curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg \\\\\n",
    "    && echo \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list \\\\\n",
    "    && apt-get update \\\\\n",
    "    && apt-get install -y docker-ce-cli\n",
    "\n",
    "# Install Python code quality tools\n",
    "RUN pip3 install \\\\\n",
    "    black \\\\\n",
    "    flake8 \\\\\n",
    "    pylint \\\\\n",
    "    mypy \\\\\n",
    "    bandit \\\\\n",
    "    safety \\\\\n",
    "    pre-commit \\\\\n",
    "    pytest \\\\\n",
    "    pytest-cov \\\\\n",
    "    coverage \\\\\n",
    "    autopep8 \\\\\n",
    "    isort \\\\\n",
    "    pipenv \\\\\n",
    "    poetry\n",
    "\n",
    "# Install Node.js code quality tools\n",
    "RUN npm install -g \\\\\n",
    "    eslint \\\\\n",
    "    prettier \\\\\n",
    "    typescript \\\\\n",
    "    @typescript-eslint/parser \\\\\n",
    "    @typescript-eslint/eslint-plugin \\\\\n",
    "    jshint \\\\\n",
    "    standard \\\\\n",
    "    stylelint \\\\\n",
    "    markdownlint-cli \\\\\n",
    "    commitizen \\\\\n",
    "    husky \\\\\n",
    "    lint-staged \\\\\n",
    "    semantic-release\n",
    "\n",
    "# Install security scanning tools\n",
    "RUN pip3 install semgrep \\\\\n",
    "    && npm install -g snyk \\\\\n",
    "    && npm install -g retire\n",
    "\n",
    "# Install Go tools\n",
    "RUN go install golang.org/x/tools/cmd/goimports@latest \\\\\n",
    "    && go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest \\\\\n",
    "    && go install github.com/securecodewarrior/gosec/v2/cmd/gosec@latest \\\\\n",
    "    && go install honnef.co/go/tools/cmd/staticcheck@latest\n",
    "\n",
    "# Install Java tools\n",
    "RUN wget https://github.com/checkstyle/checkstyle/releases/download/checkstyle-10.12.1/checkstyle-10.12.1-all.jar \\\\\n",
    "    && mv checkstyle-10.12.1-all.jar /opt/checkstyle.jar \\\\\n",
    "    && echo '#!/bin/bash\\\\njava -jar /opt/checkstyle.jar \"$@\"' > /usr/local/bin/checkstyle \\\\\n",
    "    && chmod +x /usr/local/bin/checkstyle\n",
    "\n",
    "# Install documentation tools\n",
    "RUN pip3 install \\\\\n",
    "    sphinx \\\\\n",
    "    sphinx-rtd-theme \\\\\n",
    "    mkdocs \\\\\n",
    "    mkdocs-material \\\\\n",
    "    && npm install -g \\\\\n",
    "    @apidevtools/swagger-cli \\\\\n",
    "    redoc-cli \\\\\n",
    "    jsdoc\n",
    "\n",
    "# Install performance testing tools\n",
    "RUN npm install -g \\\\\n",
    "    k6 \\\\\n",
    "    artillery \\\\\n",
    "    clinic \\\\\n",
    "    0x\n",
    "\n",
    "# Install Git hooks and conventional commits\n",
    "RUN npm install -g \\\\\n",
    "    @commitlint/cli \\\\\n",
    "    @commitlint/config-conventional \\\\\n",
    "    conventional-changelog-cli \\\\\n",
    "    cz-conventional-changelog\n",
    "\n",
    "# Install additional DevOps tools\n",
    "RUN curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\" \\\\\n",
    "    && chmod +x kubectl \\\\\n",
    "    && mv kubectl /usr/local/bin/ \\\\\n",
    "    && curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 \\\\\n",
    "    && chmod 700 get_helm.sh \\\\\n",
    "    && ./get_helm.sh \\\\\n",
    "    && rm get_helm.sh\n",
    "\n",
    "# Install Terraform\n",
    "RUN wget https://releases.hashicorp.com/terraform/1.5.3/terraform_1.5.3_linux_amd64.zip \\\\\n",
    "    && unzip terraform_1.5.3_linux_amd64.zip \\\\\n",
    "    && mv terraform /usr/local/bin/ \\\\\n",
    "    && rm terraform_1.5.3_linux_amd64.zip\n",
    "\n",
    "# Create scripts directory\n",
    "RUN mkdir -p /scripts\n",
    "\n",
    "# Create quality check script\n",
    "RUN cat > /scripts/quality-check.sh << 'EOF'\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"ðŸ” Running comprehensive code quality checks...\"\n",
    "\n",
    "# Python checks\n",
    "if find . -name \"*.py\" | head -1 | grep -q .; then\n",
    "    echo \"ðŸ“ Running Python checks...\"\n",
    "    python3 -m black --check . || echo \"âŒ Black formatting issues found\"\n",
    "    python3 -m flake8 . || echo \"âŒ Flake8 issues found\"\n",
    "    python3 -m pylint **/*.py || echo \"âŒ Pylint issues found\"\n",
    "    python3 -m bandit -r . || echo \"âŒ Security issues found\"\n",
    "fi\n",
    "\n",
    "# JavaScript/TypeScript checks\n",
    "if find . -name \"*.js\" -o -name \"*.ts\" -o -name \"*.jsx\" -o -name \"*.tsx\" | head -1 | grep -q .; then\n",
    "    echo \"ðŸ“ Running JavaScript/TypeScript checks...\"\n",
    "    npx eslint . || echo \"âŒ ESLint issues found\"\n",
    "    npx prettier --check . || echo \"âŒ Prettier formatting issues found\"\n",
    "fi\n",
    "\n",
    "# Go checks\n",
    "if find . -name \"*.go\" | head -1 | grep -q .; then\n",
    "    echo \"ðŸ“ Running Go checks...\"\n",
    "    go fmt ./... || echo \"âŒ Go formatting issues found\"\n",
    "    golangci-lint run || echo \"âŒ Go linting issues found\"\n",
    "fi\n",
    "\n",
    "echo \"âœ… Quality checks completed\"\n",
    "EOF\n",
    "\n",
    "RUN chmod +x /scripts/quality-check.sh\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Default command\n",
    "CMD [\"bash\"]\n",
    "\"\"\"\n",
    "\n",
    "# Write Development Tools Dockerfile\n",
    "os.makedirs('docker/tools', exist_ok=True)\n",
    "with open('docker/tools/dev-tools.Dockerfile', 'w') as f:\n",
    "    f.write(devtools_dockerfile.strip())\n",
    "\n",
    "print(\"âœ… Created: docker/tools/dev-tools.Dockerfile\")\n",
    "print(\"ðŸ› ï¸ Development tools container includes:\")\n",
    "print(\"   - Code formatters (Black, Prettier, gofmt)\")\n",
    "print(\"   - Linters (ESLint, Pylint, golangci-lint)\")\n",
    "print(\"   - Security scanners (Bandit, Semgrep, Snyk)\")\n",
    "print(\"   - Testing frameworks and coverage tools\")\n",
    "print(\"   - Documentation generators (Sphinx, JSDoc)\")\n",
    "print(\"   - Performance testing tools (k6, Artillery)\")\n",
    "print(\"   - Git hooks and conventional commits\")\n",
    "print(\"   - DevOps tools (kubectl, Helm, Terraform)\")\n",
    "print(\"   - Comprehensive quality check script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1fa18a",
   "metadata": {},
   "source": [
    "## 6. VS Code Dev Container Configuration\n",
    "\n",
    "### Complete IDE Integration\n",
    "\n",
    "Setting up VS Code dev containers for seamless development experience with pre-configured extensions and debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc1f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VS Code Dev Container Configuration\n",
    "devcontainer_config = {\n",
    "    \"name\": \"Universal Development Environment\",\n",
    "    \"dockerComposeFile\": \"../docker-compose.yml\",\n",
    "    \"service\": \"backend-dev\",\n",
    "    \"workspaceFolder\": \"/workspace\",\n",
    "    \"shutdownAction\": \"stopCompose\",\n",
    "    \"features\": {\n",
    "        \"ghcr.io/devcontainers/features/git:1\": {},\n",
    "        \"ghcr.io/devcontainers/features/docker-in-docker:2\": {},\n",
    "        \"ghcr.io/devcontainers/features/github-cli:1\": {}\n",
    "    },\n",
    "    \"customizations\": {\n",
    "        \"vscode\": {\n",
    "            \"extensions\": [\n",
    "                # Language Support\n",
    "                \"ms-python.python\",\n",
    "                \"ms-python.black-formatter\",\n",
    "                \"ms-python.pylint\",\n",
    "                \"ms-python.mypy-type-checker\",\n",
    "                \"ms-vscode.vscode-typescript-next\",\n",
    "                \"bradlc.vscode-tailwindcss\",\n",
    "                \"golang.go\",\n",
    "                \"rust-lang.rust-analyzer\",\n",
    "                \"redhat.java\",\n",
    "                \"vscjava.vscode-java-pack\",\n",
    "\n",
    "                # Frameworks\n",
    "                \"ms-vscode.vscode-react-native\",\n",
    "                \"Vue.volar\",\n",
    "                \"Angular.ng-template\",\n",
    "                \"svelte.svelte-vscode\",\n",
    "                \"ms-dotnettools.csharp\",\n",
    "\n",
    "                # Database\n",
    "                \"ms-mssql.mssql\",\n",
    "                \"cweijan.vscode-postgresql-client2\",\n",
    "                \"cweijan.vscode-mysql-client2\",\n",
    "                \"mongodb.mongodb-vscode\",\n",
    "                \"cweijan.vscode-redis-client\",\n",
    "\n",
    "                # DevOps and Containers\n",
    "                \"ms-vscode-remote.remote-containers\",\n",
    "                \"ms-azuretools.vscode-docker\",\n",
    "                \"ms-kubernetes-tools.vscode-kubernetes-tools\",\n",
    "                \"hashicorp.terraform\",\n",
    "                \"redhat.vscode-yaml\",\n",
    "\n",
    "                # Git and Version Control\n",
    "                \"eamodio.gitlens\",\n",
    "                \"GitHub.vscode-pull-request-github\",\n",
    "                \"GitHub.copilot\",\n",
    "                \"GitHub.copilot-chat\",\n",
    "\n",
    "                # Code Quality\n",
    "                \"esbenp.prettier-vscode\",\n",
    "                \"ms-vscode.vscode-eslint\",\n",
    "                \"streetsidesoftware.code-spell-checker\",\n",
    "                \"davidanson.vscode-markdownlint\",\n",
    "                \"shardulm94.trailing-spaces\",\n",
    "\n",
    "                # Testing\n",
    "                \"ms-vscode.test-adapter-converter\",\n",
    "                \"hbenl.vscode-test-explorer\",\n",
    "                \"ryanluker.vscode-coverage-gutters\",\n",
    "                \"ms-playwright.playwright\",\n",
    "\n",
    "                # Productivity\n",
    "                \"ms-vscode.vscode-json\",\n",
    "                \"redhat.vscode-xml\",\n",
    "                \"ms-vscode.powershell\",\n",
    "                \"formulahendry.auto-rename-tag\",\n",
    "                \"formulahendry.auto-close-tag\",\n",
    "                \"christian-kohler.path-intellisense\",\n",
    "                \"ms-vscode-remote.remote-ssh\",\n",
    "\n",
    "                # API Development\n",
    "                \"humao.rest-client\",\n",
    "                \"42Crunch.vscode-openapi\",\n",
    "                \"ms-vscode.vscode-thunder-client\",\n",
    "\n",
    "                # Themes and UI\n",
    "                \"PKief.material-icon-theme\",\n",
    "                \"zhuangtongfa.Material-theme\",\n",
    "                \"GitHub.github-vscode-theme\"\n",
    "            ],\n",
    "            \"settings\": {\n",
    "                \"python.defaultInterpreterPath\": \"/opt/venv/bin/python\",\n",
    "                \"python.terminal.activateEnvironment\": True,\n",
    "                \"python.formatting.provider\": \"black\",\n",
    "                \"python.linting.enabled\": True,\n",
    "                \"python.linting.pylintEnabled\": True,\n",
    "                \"python.testing.pytestEnabled\": True,\n",
    "                \"typescript.preferences.includePackageJsonAutoImports\": \"auto\",\n",
    "                \"eslint.validate\": [\"javascript\", \"typescript\", \"javascriptreact\", \"typescriptreact\"],\n",
    "                \"editor.formatOnSave\": True,\n",
    "                \"editor.codeActionsOnSave\": {\n",
    "                    \"source.fixAll.eslint\": True,\n",
    "                    \"source.organizeImports\": True\n",
    "                },\n",
    "                \"git.enableSmartCommit\": True,\n",
    "                \"git.confirmSync\": False,\n",
    "                \"terminal.integrated.defaultProfile.linux\": \"bash\",\n",
    "                \"workbench.colorTheme\": \"GitHub Dark\",\n",
    "                \"workbench.iconTheme\": \"material-icon-theme\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"forwardPorts\": [3000, 3001, 4200, 5173, 8000, 8080, 9000],\n",
    "    \"portsAttributes\": {\n",
    "        \"3000\": {\n",
    "            \"label\": \"Backend API\",\n",
    "            \"onAutoForward\": \"notify\"\n",
    "        },\n",
    "        \"3001\": {\n",
    "            \"label\": \"Frontend Dev Server\",\n",
    "            \"onAutoForward\": \"openPreview\"\n",
    "        }\n",
    "    },\n",
    "    \"postCreateCommand\": \"echo 'Universal Development Environment Ready!' && /scripts/setup-dev.sh\",\n",
    "    \"remoteUser\": \"developer\"\n",
    "}\n",
    "\n",
    "# Write devcontainer.json\n",
    "with open('.devcontainer/devcontainer.json', 'w') as f:\n",
    "    json.dump(devcontainer_config, f, indent=2)\n",
    "\n",
    "print(\"âœ… Created: .devcontainer/devcontainer.json\")\n",
    "print(\"ðŸŽ¯ VS Code dev container configured with:\")\n",
    "print(\"   - 40+ pre-installed extensions\")\n",
    "print(\"   - Multi-language support (Python, Node.js, Go, Java, Rust)\")\n",
    "print(\"   - Database clients and tools\")\n",
    "print(\"   - Git integration and GitHub Copilot\")\n",
    "print(\"   - Code formatting and linting\")\n",
    "print(\"   - Testing and debugging tools\")\n",
    "print(\"   - Port forwarding for all services\")\n",
    "print(\"   - Automatic environment setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fb62e",
   "metadata": {},
   "source": [
    "## 7. Language-Specific Container Patterns\n",
    "\n",
    "### Standardized Development Patterns\n",
    "\n",
    "Creating specialized container configurations for different programming languages and frameworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71a294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Language-Specific Container Configurations\n",
    "\n",
    "# Python Development Container Pattern\n",
    "python_compose = \"\"\"\n",
    "  # Python-specific development container\n",
    "  python-dev:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/python.Dockerfile\n",
    "    container_name: python-dev-env\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - python_packages:/opt/venv\n",
    "      - jupyter_data:/home/developer/.jupyter\n",
    "    ports:\n",
    "      - \"8000:8000\"   # FastAPI/Django\n",
    "      - \"8888:8888\"   # Jupyter\n",
    "      - \"6006:6006\"   # TensorBoard\n",
    "      - \"5000:5000\"   # Flask\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - PYTHONPATH=/workspace\n",
    "      - JUPYTER_ENABLE_LAB=yes\n",
    "      - PYTHONDONTWRITEBYTECODE=1\n",
    "      - PYTHONUNBUFFERED=1\n",
    "    command: jupyter lab --ip=0.0.0.0 --allow-root --no-browser\n",
    "\"\"\"\n",
    "\n",
    "# Node.js Development Container Pattern\n",
    "nodejs_compose = \"\"\"\n",
    "  # Node.js-specific development container\n",
    "  nodejs-dev:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/nodejs.Dockerfile\n",
    "    container_name: nodejs-dev-env\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - node_modules:/workspace/node_modules\n",
    "      - npm_cache:/home/developer/.npm\n",
    "    ports:\n",
    "      - \"3000:3000\"   # Express/NestJS\n",
    "      - \"3001:3001\"   # Next.js\n",
    "      - \"4000:4000\"   # GraphQL\n",
    "      - \"5173:5173\"   # Vite\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - NODE_ENV=development\n",
    "      - CHOKIDAR_USEPOLLING=true\n",
    "      - FAST_REFRESH=true\n",
    "    command: npm run dev\n",
    "\"\"\"\n",
    "\n",
    "# Go Development Container Pattern\n",
    "go_compose = \"\"\"\n",
    "  # Go-specific development container\n",
    "  go-dev:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/go.Dockerfile\n",
    "    container_name: go-dev-env\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - go_modules:/go/pkg/mod\n",
    "    ports:\n",
    "      - \"8080:8080\"   # Go web server\n",
    "      - \"9090:9090\"   # Go metrics\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - GO111MODULE=on\n",
    "      - GOPROXY=https://proxy.golang.org\n",
    "      - CGO_ENABLED=1\n",
    "    command: air -c .air.toml\n",
    "\"\"\"\n",
    "\n",
    "# Multi-Language Project Pattern\n",
    "multiproject_compose = \"\"\"\n",
    "  # Multi-language orchestration\n",
    "  api-gateway:\n",
    "    image: nginx:alpine\n",
    "    container_name: dev-api-gateway\n",
    "    volumes:\n",
    "      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "      - \"443:443\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    depends_on:\n",
    "      - backend-dev\n",
    "      - frontend-dev\n",
    "      - python-dev\n",
    "      - nodejs-dev\n",
    "      - go-dev\n",
    "\n",
    "  monitoring:\n",
    "    image: prom/prometheus:latest\n",
    "    container_name: dev-monitoring\n",
    "    volumes:\n",
    "      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n",
    "      - prometheus_data:/prometheus\n",
    "    ports:\n",
    "      - \"9090:9090\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    command:\n",
    "      - '--config.file=/etc/prometheus/prometheus.yml'\n",
    "      - '--storage.tsdb.path=/prometheus'\n",
    "      - '--web.console.libraries=/etc/prometheus/console_libraries'\n",
    "      - '--web.console.templates=/etc/prometheus/consoles'\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ… Language-specific container patterns created\")\n",
    "print(\"ðŸ”§ Specialized configurations include:\")\n",
    "print(\"   - Python: FastAPI, Django, Jupyter, ML frameworks\")\n",
    "print(\"   - Node.js: Express, Next.js, React, Vue with hot reload\")\n",
    "print(\"   - Go: Gin, fiber with live reload using Air\")\n",
    "print(\"   - Multi-language: API gateway, monitoring, orchestration\")\n",
    "print(\"   - Optimized volumes and caching for each language\")\n",
    "print(\"   - Framework-specific development servers\")\n",
    "print(\"   - Language-specific debugging and profiling tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a499e",
   "metadata": {},
   "source": [
    "## 8. Production Container Optimization\n",
    "\n",
    "### Lean, Secure Production Containers\n",
    "\n",
    "Creating optimized production containers with multi-stage builds, security best practices, and minimal attack surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4581b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Production-Optimized Dockerfiles\n",
    "\n",
    "# Production Python Container\n",
    "python_prod_dockerfile = \"\"\"\n",
    "# Multi-stage build for Python production\n",
    "FROM python:3.11-slim as builder\n",
    "\n",
    "# Install build dependencies\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    build-essential \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Create virtual environment\n",
    "RUN python -m venv /opt/venv\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "\n",
    "# Copy requirements and install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Production stage\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# Create non-root user\n",
    "RUN groupadd -r appuser && useradd -r -g appuser appuser\n",
    "\n",
    "# Copy virtual environment from builder\n",
    "COPY --from=builder /opt/venv /opt/venv\n",
    "ENV PATH=\"/opt/venv/bin:$PATH\"\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy application code\n",
    "COPY --chown=appuser:appuser . .\n",
    "\n",
    "# Security: Remove unnecessary packages and files\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\\\n",
    "    && rm -rf /var/lib/apt/lists/* \\\\\n",
    "    && rm -rf /tmp/* \\\\\n",
    "    && rm -rf /var/cache/*\n",
    "\n",
    "# Switch to non-root user\n",
    "USER appuser\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\\\n",
    "    CMD curl -f http://localhost:8000/health || exit 1\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 8000\n",
    "\n",
    "# Run application\n",
    "CMD [\"python\", \"-m\", \"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "\"\"\"\n",
    "\n",
    "# Production Node.js Container\n",
    "nodejs_prod_dockerfile = \"\"\"\n",
    "# Multi-stage build for Node.js production\n",
    "FROM node:18-alpine as builder\n",
    "\n",
    "# Install build dependencies\n",
    "RUN apk add --no-cache python3 make g++\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy package files\n",
    "COPY package*.json ./\n",
    "COPY yarn.lock ./\n",
    "\n",
    "# Install dependencies\n",
    "RUN npm ci --only=production && npm cache clean --force\n",
    "\n",
    "# Production stage\n",
    "FROM node:18-alpine\n",
    "\n",
    "# Create non-root user\n",
    "RUN addgroup -g 1001 -S nodejs && adduser -S nextjs -u 1001\n",
    "\n",
    "# Install only runtime dependencies\n",
    "RUN apk add --no-cache dumb-init\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy built application\n",
    "COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules\n",
    "COPY --chown=nextjs:nodejs . .\n",
    "\n",
    "# Remove development files\n",
    "RUN rm -rf src/ tests/ *.test.js *.spec.js\n",
    "\n",
    "# Switch to non-root user\n",
    "USER nextjs\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\\\n",
    "    CMD wget --no-verbose --tries=1 --spider http://localhost:3000/health || exit 1\n",
    "\n",
    "EXPOSE 3000\n",
    "\n",
    "# Use dumb-init to handle signals properly\n",
    "ENTRYPOINT [\"dumb-init\", \"--\"]\n",
    "CMD [\"node\", \"server.js\"]\n",
    "\"\"\"\n",
    "\n",
    "# Production Go Container\n",
    "go_prod_dockerfile = \"\"\"\n",
    "# Multi-stage build for Go production\n",
    "FROM golang:1.21-alpine AS builder\n",
    "\n",
    "# Install git and ca-certificates (needed for go mod download)\n",
    "RUN apk add --no-cache git ca-certificates\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy go mod files\n",
    "COPY go.mod go.sum ./\n",
    "\n",
    "# Download dependencies\n",
    "RUN go mod download\n",
    "\n",
    "# Copy source code\n",
    "COPY . .\n",
    "\n",
    "# Build the binary with optimizations\n",
    "RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .\n",
    "\n",
    "# Production stage using distroless\n",
    "FROM gcr.io/distroless/static:nonroot\n",
    "\n",
    "# Copy the binary from builder\n",
    "COPY --from=builder /app/main /\n",
    "\n",
    "# Health check (if supported by distroless variant)\n",
    "# HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\\\n",
    "#     CMD [\"/main\", \"health\"] || exit 1\n",
    "\n",
    "EXPOSE 8080\n",
    "\n",
    "# Run as non-root user\n",
    "USER nonroot:nonroot\n",
    "\n",
    "ENTRYPOINT [\"/main\"]\n",
    "\"\"\"\n",
    "\n",
    "# Write production Dockerfiles\n",
    "os.makedirs('docker/production', exist_ok=True)\n",
    "\n",
    "with open('docker/production/python.Dockerfile', 'w') as f:\n",
    "    f.write(python_prod_dockerfile.strip())\n",
    "\n",
    "with open('docker/production/nodejs.Dockerfile', 'w') as f:\n",
    "    f.write(nodejs_prod_dockerfile.strip())\n",
    "\n",
    "with open('docker/production/go.Dockerfile', 'w') as f:\n",
    "    f.write(go_prod_dockerfile.strip())\n",
    "\n",
    "print(\"âœ… Created production-optimized Dockerfiles:\")\n",
    "print(\"   - docker/production/python.Dockerfile\")\n",
    "print(\"   - docker/production/nodejs.Dockerfile\")\n",
    "print(\"   - docker/production/go.Dockerfile\")\n",
    "print(\"\")\n",
    "print(\"ðŸ”’ Production optimizations include:\")\n",
    "print(\"   - Multi-stage builds for minimal image size\")\n",
    "print(\"   - Non-root users for security\")\n",
    "print(\"   - Distroless/Alpine base images\")\n",
    "print(\"   - Health checks and proper signal handling\")\n",
    "print(\"   - Removed development dependencies\")\n",
    "print(\"   - Security-hardened configurations\")\n",
    "print(\"   - Optimized layer caching\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3a098",
   "metadata": {},
   "source": [
    "## 9. Computer Vision and Camera Calibration Container Environment\n",
    "\n",
    "### Specialized Computer Vision Development Stack\n",
    "\n",
    "Creating a dedicated computer vision development environment with camera calibration algorithms, stereo vision processing, and advanced CV libraries:\n",
    "\n",
    "#### Camera Calibration Theory and Implementation\n",
    "\n",
    "Camera calibration is fundamental to computer vision applications, particularly stereo vision systems. The containerized environment provides implementations of multiple calibration algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Computer Vision Development Container\n",
    "cv_dockerfile = \"\"\"\n",
    "FROM ubuntu:22.04 as cv-base\n",
    "\n",
    "ENV DEBIAN_FRONTEND=noninteractive\n",
    "\n",
    "# Install system dependencies for computer vision\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    build-essential \\\\\n",
    "    cmake \\\\\n",
    "    pkg-config \\\\\n",
    "    libjpeg-dev \\\\\n",
    "    libtiff5-dev \\\\\n",
    "    libpng-dev \\\\\n",
    "    libavcodec-dev \\\\\n",
    "    libavformat-dev \\\\\n",
    "    libswscale-dev \\\\\n",
    "    libv4l-dev \\\\\n",
    "    libxvidcore-dev \\\\\n",
    "    libx264-dev \\\\\n",
    "    libgtk-3-dev \\\\\n",
    "    libatlas-base-dev \\\\\n",
    "    gfortran \\\\\n",
    "    python3 \\\\\n",
    "    python3-dev \\\\\n",
    "    python3-pip \\\\\n",
    "    python3-venv \\\\\n",
    "    libhdf5-serial-dev \\\\\n",
    "    libhdf5-dev \\\\\n",
    "    libhdf5-103 \\\\\n",
    "    qt5-qmake \\\\\n",
    "    qt5-default \\\\\n",
    "    libvtk9-dev \\\\\n",
    "    libpcl-dev \\\\\n",
    "    git \\\\\n",
    "    wget \\\\\n",
    "    curl \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install OpenCV with optimizations\n",
    "FROM cv-base as opencv-builder\n",
    "\n",
    "WORKDIR /tmp\n",
    "\n",
    "# Download OpenCV and contrib modules\n",
    "RUN wget -O opencv.zip https://github.com/opencv/opencv/archive/4.8.0.zip \\\\\n",
    "    && wget -O opencv_contrib.zip https://github.com/opencv/opencv_contrib/archive/4.8.0.zip \\\\\n",
    "    && unzip opencv.zip \\\\\n",
    "    && unzip opencv_contrib.zip \\\\\n",
    "    && mv opencv-4.8.0 opencv \\\\\n",
    "    && mv opencv_contrib-4.8.0 opencv_contrib\n",
    "\n",
    "# Build OpenCV with camera calibration and stereo vision support\n",
    "RUN cd opencv && mkdir build && cd build \\\\\n",
    "    && cmake -D CMAKE_BUILD_TYPE=RELEASE \\\\\n",
    "        -D CMAKE_INSTALL_PREFIX=/usr/local \\\\\n",
    "        -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib/modules \\\\\n",
    "        -D ENABLE_CXX11=ON \\\\\n",
    "        -D BUILD_TESTS=OFF \\\\\n",
    "        -D BUILD_PERF_TESTS=OFF \\\\\n",
    "        -D BUILD_EXAMPLES=ON \\\\\n",
    "        -D OPENCV_ENABLE_NONFREE=ON \\\\\n",
    "        -D WITH_TBB=ON \\\\\n",
    "        -D WITH_V4L=ON \\\\\n",
    "        -D WITH_QT=ON \\\\\n",
    "        -D WITH_OPENGL=ON \\\\\n",
    "        -D WITH_VTK=ON \\\\\n",
    "        -D BUILD_opencv_stereo=ON \\\\\n",
    "        -D BUILD_opencv_calib3d=ON \\\\\n",
    "        -D BUILD_opencv_ximgproc=ON \\\\\n",
    "        .. \\\\\n",
    "    && make -j$(nproc) \\\\\n",
    "    && make install \\\\\n",
    "    && ldconfig\n",
    "\n",
    "# Final computer vision development image\n",
    "FROM cv-base\n",
    "\n",
    "# Copy OpenCV from builder\n",
    "COPY --from=opencv-builder /usr/local /usr/local\n",
    "RUN ldconfig\n",
    "\n",
    "# Create virtual environment for Python\n",
    "RUN python3 -m venv /opt/cv-venv\n",
    "ENV PATH=\"/opt/cv-venv/bin:$PATH\"\n",
    "\n",
    "# Install Python computer vision libraries\n",
    "RUN pip install --upgrade pip && pip install \\\\\n",
    "    numpy \\\\\n",
    "    scipy \\\\\n",
    "    matplotlib \\\\\n",
    "    opencv-python \\\\\n",
    "    opencv-contrib-python \\\\\n",
    "    scikit-image \\\\\n",
    "    pillow \\\\\n",
    "    imageio \\\\\n",
    "    plotly \\\\\n",
    "    jupyter \\\\\n",
    "    notebook \\\\\n",
    "    ipywidgets \\\\\n",
    "    open3d \\\\\n",
    "    vtk \\\\\n",
    "    mayavi \\\\\n",
    "    pyntcloud \\\\\n",
    "    trimesh \\\\\n",
    "    meshio \\\\\n",
    "    pyceres \\\\\n",
    "    pycolmap\n",
    "\n",
    "# Install calibration-specific libraries\n",
    "RUN pip install \\\\\n",
    "    camera-calibration-parsers \\\\\n",
    "    camera-calibration \\\\\n",
    "    stereo-image-proc \\\\\n",
    "    bundle-adjustment \\\\\n",
    "    visual-odometry\n",
    "\n",
    "# Create development user\n",
    "RUN useradd -m -s /bin/bash cvdev \\\\\n",
    "    && usermod -aG sudo cvdev \\\\\n",
    "    && echo 'cvdev ALL=(ALL) NOPASSWD:ALL' >> /etc/sudoers\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /workspace\n",
    "\n",
    "# Copy calibration scripts and examples\n",
    "COPY docker/cv/calibration_examples/ /workspace/examples/\n",
    "COPY docker/cv/scripts/ /workspace/scripts/\n",
    "\n",
    "# Expose Jupyter port\n",
    "EXPOSE 8888\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \\\\\n",
    "    CMD python3 -c \"import cv2, numpy, scipy; print('CV environment ready')\"\n",
    "\n",
    "USER cvdev\n",
    "\n",
    "# Default command starts Jupyter for interactive development\n",
    "CMD [\"jupyter\", \"lab\", \"--ip=0.0.0.0\", \"--port=8888\", \"--no-browser\", \"--allow-root\"]\n",
    "\"\"\"\n",
    "\n",
    "# Write Computer Vision Dockerfile\n",
    "os.makedirs('docker/development', exist_ok=True)\n",
    "with open('docker/development/computer-vision.Dockerfile', 'w') as f:\n",
    "    f.write(cv_dockerfile.strip())\n",
    "\n",
    "print(\"âœ… Created: docker/development/computer-vision.Dockerfile\")\n",
    "print(\"ðŸ“¸ Computer vision container includes:\")\n",
    "print(\"   - OpenCV 4.8.0 with contrib modules\")\n",
    "print(\"   - Camera calibration and stereo vision support\")\n",
    "print(\"   - Python scientific computing stack\")\n",
    "print(\"   - 3D processing libraries (Open3D, VTK)\")\n",
    "print(\"   - Jupyter Lab for interactive development\")\n",
    "print(\"   - Optimized build with TBB and Qt support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d66821",
   "metadata": {},
   "source": [
    "### Camera Calibration Algorithms Implementation\n",
    "\n",
    "#### 1. Eight-Point Algorithm (Longuet-Higgins)\n",
    "\n",
    "The eight-point algorithm estimates the fundamental matrix F that relates corresponding points between stereo images. For points x (left) and x' (right) in homogeneous coordinates: **x'áµ€Fx = 0**\n",
    "\n",
    "**Algorithm Steps:**\n",
    "1. **Linear System Formation**: Create homogeneous equations from 8+ point correspondences\n",
    "2. **SVD Solution**: Solve using Singular Value Decomposition \n",
    "3. **Constraint Enforcement**: Essential matrix has two equal non-zero singular values and one zero\n",
    "\n",
    "#### 2. Tsai's Two-Stage Calibration\n",
    "\n",
    "Based on the **Radial Alignment Constraint (RAC)** assuming radial distortion exists:\n",
    "\n",
    "**Key Principles:**\n",
    "- Direction from optical center Oáµ¢ to distorted point (Xd, Yd) is radially aligned with vector PozP\n",
    "- Same direction aligns with vector to undistorted point (Xu, Yu)\n",
    "- Enables separation of intrinsic and extrinsic parameter estimation\n",
    "\n",
    "#### Container Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02229c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create camera calibration implementation scripts\n",
    "calibration_scripts = {\n",
    "    \"eight_point_algorithm.py\": \"\"\"#!/usr/bin/env python3\n",
    "\\\"\\\"\\\"\n",
    "Eight-Point Algorithm Implementation for Fundamental Matrix Estimation\n",
    "Based on Longuet-Higgins method for stereo camera calibration\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.linalg import svd\n",
    "\n",
    "class EightPointCalibration:\n",
    "    def __init__(self):\n",
    "        self.fundamental_matrix = None\n",
    "        self.essential_matrix = None\n",
    "\n",
    "    def estimate_fundamental_matrix(self, pts1, pts2, method='8point'):\n",
    "        \\\"\\\"\\\"\n",
    "        Estimate fundamental matrix from corresponding points\n",
    "\n",
    "        Args:\n",
    "            pts1: Points in left image (Nx2)\n",
    "            pts2: Points in right image (Nx2)\n",
    "            method: '8point', 'ransac', or 'lmeds'\n",
    "        \\\"\\\"\\\"\n",
    "        pts1 = np.float32(pts1).reshape(-1, 1, 2)\n",
    "        pts2 = np.float32(pts2).reshape(-1, 1, 2)\n",
    "\n",
    "        if method == '8point':\n",
    "            F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_8POINT)\n",
    "        elif method == 'ransac':\n",
    "            F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC, 3.0, 0.99)\n",
    "        else:\n",
    "            F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_LMEDS)\n",
    "\n",
    "        self.fundamental_matrix = F\n",
    "        return F, mask\n",
    "\n",
    "    def fundamental_to_essential(self, F, K1, K2):\n",
    "        \\\"\\\"\\\"Convert fundamental matrix to essential matrix\\\"\\\"\\\"\n",
    "        E = K2.T @ F @ K1\n",
    "\n",
    "        # Enforce essential matrix constraints\n",
    "        U, S, Vt = svd(E)\n",
    "        S = np.array([1, 1, 0])  # Two equal non-zero, one zero\n",
    "        E = U @ np.diag(S) @ Vt\n",
    "\n",
    "        self.essential_matrix = E\n",
    "        return E\n",
    "\n",
    "    def decompose_essential_matrix(self, E):\n",
    "        \\\"\\\"\\\"\n",
    "        Decompose essential matrix into rotation and translation\n",
    "        Returns 4 possible solutions\n",
    "        \\\"\\\"\\\"\n",
    "        U, S, Vt = svd(E)\n",
    "\n",
    "        # Ensure proper rotation matrix\n",
    "        if np.linalg.det(U) < 0:\n",
    "            U *= -1\n",
    "        if np.linalg.det(Vt) < 0:\n",
    "            Vt *= -1\n",
    "\n",
    "        W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "\n",
    "        # Four possible solutions\n",
    "        R1 = U @ W @ Vt\n",
    "        R2 = U @ W.T @ Vt\n",
    "        t1 = U[:, 2]\n",
    "        t2 = -U[:, 2]\n",
    "\n",
    "        return [(R1, t1), (R1, t2), (R2, t1), (R2, t2)]\n",
    "\n",
    "    def select_correct_pose(self, poses, pts1, pts2, K1, K2):\n",
    "        \\\"\\\"\\\"Select pose with positive depth for all points\\\"\\\"\\\"\n",
    "        best_pose = None\n",
    "        max_positive = 0\n",
    "\n",
    "        for R, t in poses:\n",
    "            # Triangulate points\n",
    "            P1 = K1 @ np.hstack([np.eye(3), np.zeros((3, 1))])\n",
    "            P2 = K2 @ np.hstack([R, t.reshape(-1, 1)])\n",
    "\n",
    "            points_4d = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "            points_3d = points_4d[:3] / points_4d[3]\n",
    "\n",
    "            # Check positive depth\n",
    "            positive_depth = np.sum(points_3d[2] > 0)\n",
    "\n",
    "            if positive_depth > max_positive:\n",
    "                max_positive = positive_depth\n",
    "                best_pose = (R, t)\n",
    "\n",
    "        return best_pose\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    calibrator = EightPointCalibration()\n",
    "    print(\"Eight-point algorithm calibration ready\")\n",
    "\"\"\",\n",
    "\n",
    "    \"tsai_calibration.py\": \"\"\"#!/usr/bin/env python3\n",
    "\\\"\\\"\\\"\n",
    "Tsai's Two-Stage Calibration Algorithm Implementation\n",
    "Based on Radial Alignment Constraint (RAC)\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "class TsaiCalibration:\n",
    "    def __init__(self):\n",
    "        self.intrinsic_matrix = None\n",
    "        self.distortion_coeffs = None\n",
    "        self.rotation_matrix = None\n",
    "        self.translation_vector = None\n",
    "\n",
    "    def calibrate_camera(self, object_points, image_points, image_size):\n",
    "        \\\"\\\"\\\"\n",
    "        Two-stage calibration process\n",
    "\n",
    "        Args:\n",
    "            object_points: 3D points in world coordinate system\n",
    "            image_points: 2D points in image coordinate system\n",
    "            image_size: Size of calibration images\n",
    "        \\\"\\\"\\\"\n",
    "        # Stage 1: Estimate extrinsic parameters using RAC\n",
    "        R_initial, t_initial = self._stage1_extrinsic_estimation(\n",
    "            object_points, image_points)\n",
    "\n",
    "        # Stage 2: Refine all parameters with nonlinear optimization\n",
    "        params_optimized = self._stage2_nonlinear_optimization(\n",
    "            object_points, image_points, R_initial, t_initial, image_size)\n",
    "\n",
    "        return params_optimized\n",
    "\n",
    "    def _stage1_extrinsic_estimation(self, object_points, image_points):\n",
    "        \\\"\\\"\\\"\n",
    "        Stage 1: Estimate extrinsic parameters using RAC constraint\n",
    "\n",
    "        The radial alignment constraint states that the direction from\n",
    "        the optical center to a distorted image point is radially aligned\n",
    "        with the corresponding 3D object point.\n",
    "        \\\"\\\"\\\"\n",
    "        # Estimate initial pose using PnP\n",
    "        # Assume initial intrinsic parameters\n",
    "        K_initial = np.array([[800, 0, 320],\n",
    "                             [0, 800, 240],\n",
    "                             [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "        success, rvec, tvec = cv2.solvePnP(\n",
    "            object_points.astype(np.float32),\n",
    "            image_points.astype(np.float32),\n",
    "            K_initial,\n",
    "            None\n",
    "        )\n",
    "\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        return R, tvec.flatten()\n",
    "\n",
    "    def _stage2_nonlinear_optimization(self, object_points, image_points,\n",
    "                                     R_init, t_init, image_size):\n",
    "        \\\"\\\"\\\"\n",
    "        Stage 2: Nonlinear optimization of all parameters\n",
    "\n",
    "        Refines intrinsic parameters, distortion coefficients,\n",
    "        and extrinsic parameters simultaneously.\n",
    "        \\\"\\\"\\\"\n",
    "        # Initial parameter vector\n",
    "        # [fx, fy, cx, cy, k1, k2, p1, p2, rx, ry, rz, tx, ty, tz]\n",
    "        rvec_init, _ = cv2.Rodrigues(R_init)\n",
    "\n",
    "        initial_params = np.array([\n",
    "            800.0, 800.0,  # fx, fy\n",
    "            image_size[0]/2, image_size[1]/2,  # cx, cy\n",
    "            0.0, 0.0, 0.0, 0.0,  # distortion coefficients\n",
    "            rvec_init[0, 0], rvec_init[1, 0], rvec_init[2, 0],  # rotation\n",
    "            t_init[0], t_init[1], t_init[2]  # translation\n",
    "        ])\n",
    "\n",
    "        # Optimization\n",
    "        result = least_squares(\n",
    "            self._reprojection_error,\n",
    "            initial_params,\n",
    "            args=(object_points, image_points),\n",
    "            method='lm'\n",
    "        )\n",
    "\n",
    "        optimized_params = result.x\n",
    "        return self._parse_optimized_parameters(optimized_params)\n",
    "\n",
    "    def _reprojection_error(self, params, object_points, image_points):\n",
    "        \\\"\\\"\\\"Calculate reprojection error for optimization\\\"\\\"\\\"\n",
    "        fx, fy, cx, cy, k1, k2, p1, p2, rx, ry, rz, tx, ty, tz = params\n",
    "\n",
    "        # Construct camera matrix\n",
    "        K = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "\n",
    "        # Distortion coefficients\n",
    "        dist_coeffs = np.array([k1, k2, p1, p2])\n",
    "\n",
    "        # Rotation and translation\n",
    "        rvec = np.array([rx, ry, rz])\n",
    "        tvec = np.array([tx, ty, tz])\n",
    "\n",
    "        # Project points\n",
    "        projected_points, _ = cv2.projectPoints(\n",
    "            object_points, rvec, tvec, K, dist_coeffs)\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals = (projected_points.reshape(-1, 2) -\n",
    "                    image_points.reshape(-1, 2)).flatten()\n",
    "\n",
    "        return residuals\n",
    "\n",
    "    def _parse_optimized_parameters(self, params):\n",
    "        \\\"\\\"\\\"Parse optimized parameter vector into matrices\\\"\\\"\\\"\n",
    "        fx, fy, cx, cy, k1, k2, p1, p2, rx, ry, rz, tx, ty, tz = params\n",
    "\n",
    "        self.intrinsic_matrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "        self.distortion_coeffs = np.array([k1, k2, p1, p2])\n",
    "\n",
    "        rvec = np.array([rx, ry, rz])\n",
    "        self.rotation_matrix, _ = cv2.Rodrigues(rvec)\n",
    "        self.translation_vector = np.array([tx, ty, tz])\n",
    "\n",
    "        return {\n",
    "            'camera_matrix': self.intrinsic_matrix,\n",
    "            'distortion_coefficients': self.distortion_coeffs,\n",
    "            'rotation_matrix': self.rotation_matrix,\n",
    "            'translation_vector': self.translation_vector\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    calibrator = TsaiCalibration()\n",
    "    print(\"Tsai two-stage calibration ready\")\n",
    "\"\"\",\n",
    "\n",
    "    \"stereo_calibration.py\": \"\"\"#!/usr/bin/env python3\n",
    "\\\"\\\"\\\"\n",
    "Stereo Camera Calibration Implementation\n",
    "Combines both eight-point and Tsai methods for robust stereo calibration\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from eight_point_algorithm import EightPointCalibration\n",
    "from tsai_calibration import TsaiCalibration\n",
    "\n",
    "class StereoCalibration:\n",
    "    def __init__(self):\n",
    "        self.left_camera_matrix = None\n",
    "        self.right_camera_matrix = None\n",
    "        self.left_distortion = None\n",
    "        self.right_distortion = None\n",
    "        self.rotation_matrix = None\n",
    "        self.translation_vector = None\n",
    "        self.essential_matrix = None\n",
    "        self.fundamental_matrix = None\n",
    "\n",
    "    def calibrate_stereo_system(self, left_object_points, right_object_points,\n",
    "                               left_image_points, right_image_points,\n",
    "                               image_size):\n",
    "        \\\"\\\"\\\"\n",
    "        Complete stereo calibration using combined approach\n",
    "        \\\"\\\"\\\"\n",
    "        # Step 1: Individual camera calibration using Tsai method\n",
    "        left_calib = TsaiCalibration()\n",
    "        right_calib = TsaiCalibration()\n",
    "\n",
    "        left_params = left_calib.calibrate_camera(\n",
    "            left_object_points, left_image_points, image_size)\n",
    "        right_params = right_calib.calibrate_camera(\n",
    "            right_object_points, right_image_points, image_size)\n",
    "\n",
    "        # Step 2: Stereo calibration refinement\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "        ret, K1, D1, K2, D2, R, T, E, F = cv2.stereoCalibrate(\n",
    "            left_object_points, left_image_points, right_image_points,\n",
    "            left_params['camera_matrix'], left_params['distortion_coefficients'],\n",
    "            right_params['camera_matrix'], right_params['distortion_coefficients'],\n",
    "            image_size, criteria=criteria,\n",
    "            flags=cv2.CALIB_FIX_INTRINSIC)\n",
    "\n",
    "        # Step 3: Verify with eight-point algorithm\n",
    "        eight_point = EightPointCalibration()\n",
    "        F_verify, _ = eight_point.estimate_fundamental_matrix(\n",
    "            left_image_points.reshape(-1, 2),\n",
    "            right_image_points.reshape(-1, 2))\n",
    "\n",
    "        # Store results\n",
    "        self.left_camera_matrix = K1\n",
    "        self.right_camera_matrix = K2\n",
    "        self.left_distortion = D1\n",
    "        self.right_distortion = D2\n",
    "        self.rotation_matrix = R\n",
    "        self.translation_vector = T\n",
    "        self.essential_matrix = E\n",
    "        self.fundamental_matrix = F\n",
    "\n",
    "        return {\n",
    "            'left_camera_matrix': K1,\n",
    "            'right_camera_matrix': K2,\n",
    "            'left_distortion': D1,\n",
    "            'right_distortion': D2,\n",
    "            'rotation': R,\n",
    "            'translation': T,\n",
    "            'essential_matrix': E,\n",
    "            'fundamental_matrix': F,\n",
    "            'fundamental_verify': F_verify,\n",
    "            'calibration_error': ret\n",
    "        }\n",
    "\n",
    "    def rectify_stereo_images(self, left_img, right_img):\n",
    "        \\\"\\\"\\\"Rectify stereo image pair for disparity computation\\\"\\\"\\\"\n",
    "        h, w = left_img.shape[:2]\n",
    "\n",
    "        R1, R2, P1, P2, Q, _, _ = cv2.stereoRectify(\n",
    "            self.left_camera_matrix, self.left_distortion,\n",
    "            self.right_camera_matrix, self.right_distortion,\n",
    "            (w, h), self.rotation_matrix, self.translation_vector)\n",
    "\n",
    "        map1_left, map2_left = cv2.initUndistortRectifyMap(\n",
    "            self.left_camera_matrix, self.left_distortion, R1, P1, (w, h), cv2.CV_16SC2)\n",
    "        map1_right, map2_right = cv2.initUndistortRectifyMap(\n",
    "            self.right_camera_matrix, self.right_distortion, R2, P2, (w, h), cv2.CV_16SC2)\n",
    "\n",
    "        left_rectified = cv2.remap(left_img, map1_left, map2_left, cv2.INTER_LINEAR)\n",
    "        right_rectified = cv2.remap(right_img, map1_right, map2_right, cv2.INTER_LINEAR)\n",
    "\n",
    "        return left_rectified, right_rectified, Q\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    stereo_calib = StereoCalibration()\n",
    "    print(\"Stereo calibration system ready\")\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# Create calibration scripts directory and files\n",
    "os.makedirs('docker/cv/scripts', exist_ok=True)\n",
    "\n",
    "for filename, content in calibration_scripts.items():\n",
    "    with open(f'docker/cv/scripts/{filename}', 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"âœ… Created camera calibration implementation scripts:\")\n",
    "for filename in calibration_scripts.keys():\n",
    "    print(f\"   - docker/cv/scripts/{filename}\")\n",
    "\n",
    "print(\"\\nðŸ“ Calibration algorithms implemented:\")\n",
    "print(\"   - Eight-point algorithm with SVD solution\")\n",
    "print(\"   - Tsai's two-stage calibration with RAC constraint\")\n",
    "print(\"   - Combined stereo calibration system\")\n",
    "print(\"   - Fundamental and essential matrix estimation\")\n",
    "print(\"   - Stereo rectification and disparity computation\")\n",
    "print(\"   - Robust pose estimation with depth validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Computer Vision Docker Compose Configuration\n",
    "cv_compose_config = \"\"\"\n",
    "# Computer Vision Development Services\n",
    "services:\n",
    "  # Computer vision development container\n",
    "  cv-dev:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/computer-vision.Dockerfile\n",
    "    container_name: cv-development\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - cv_datasets:/workspace/datasets\n",
    "      - cv_models:/workspace/models\n",
    "      - cv_calibration:/workspace/calibration_data\n",
    "      - jupyter_notebooks:/workspace/notebooks\n",
    "    ports:\n",
    "      - \"8888:8888\"   # Jupyter Lab\n",
    "      - \"6006:6006\"   # TensorBoard\n",
    "      - \"8080:8080\"   # CV web interface\n",
    "      - \"5000:5000\"   # Flask/FastAPI for CV APIs\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - JUPYTER_ENABLE_LAB=yes\n",
    "      - OPENCV_VERSION=4.8.0\n",
    "      - CUDA_VISIBLE_DEVICES=0  # Enable GPU if available\n",
    "    devices:\n",
    "      - /dev/video0:/dev/video0  # Camera access\n",
    "      - /dev/video1:/dev/video1  # Second camera for stereo\n",
    "    privileged: true  # For camera access\n",
    "    command: bash -c \"cd /workspace && jupyter lab --ip=0.0.0.0 --allow-root --no-browser\"\n",
    "\n",
    "  # Camera calibration service\n",
    "  calibration-service:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/computer-vision.Dockerfile\n",
    "    container_name: cv-calibration-service\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - cv_calibration:/workspace/calibration_data\n",
    "      - cv_datasets:/workspace/datasets\n",
    "    ports:\n",
    "      - \"5001:5000\"   # Calibration API\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - FLASK_ENV=development\n",
    "      - CALIBRATION_DATA_PATH=/workspace/calibration_data\n",
    "    command: python /workspace/scripts/calibration_service.py\n",
    "\n",
    "  # Stereo vision processing service\n",
    "  stereo-processor:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: docker/development/computer-vision.Dockerfile\n",
    "    container_name: cv-stereo-processor\n",
    "    volumes:\n",
    "      - .:/workspace:cached\n",
    "      - cv_datasets:/workspace/datasets\n",
    "      - cv_results:/workspace/results\n",
    "    ports:\n",
    "      - \"5002:5000\"   # Stereo processing API\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - PROCESSING_THREADS=4\n",
    "      - STEREO_ALGORITHM=SGBM  # or BM, ELAS, etc.\n",
    "    depends_on:\n",
    "      - calibration-service\n",
    "    command: python /workspace/scripts/stereo_service.py\n",
    "\n",
    "  # Computer vision database for storing calibration data\n",
    "  cv-database:\n",
    "    image: postgres:15-alpine\n",
    "    container_name: cv-postgres\n",
    "    volumes:\n",
    "      - cv_db_data:/var/lib/postgresql/data\n",
    "      - ./docker/cv/init-cv-db.sql:/docker-entrypoint-initdb.d/init.sql\n",
    "    ports:\n",
    "      - \"5433:5432\"\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - POSTGRES_DB=computer_vision\n",
    "      - POSTGRES_USER=cvuser\n",
    "      - POSTGRES_PASSWORD=cvpass\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U cvuser -d computer_vision\"]\n",
    "      interval: 10s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  # MinIO for storing large datasets and models\n",
    "  cv-storage:\n",
    "    image: minio/minio:latest\n",
    "    container_name: cv-minio\n",
    "    volumes:\n",
    "      - cv_storage_data:/data\n",
    "    ports:\n",
    "      - \"9002:9000\"   # API\n",
    "      - \"9003:9001\"   # Console\n",
    "    networks:\n",
    "      - dev-network\n",
    "    environment:\n",
    "      - MINIO_ROOT_USER=cvadmin\n",
    "      - MINIO_ROOT_PASSWORD=cvadmin123\n",
    "      - MINIO_DEFAULT_BUCKETS=datasets,models,calibration,results\n",
    "    command: server /data --console-address \":9001\"\n",
    "\n",
    "# Additional volumes for computer vision\n",
    "volumes:\n",
    "  cv_datasets:\n",
    "    driver: local\n",
    "  cv_models:\n",
    "    driver: local\n",
    "  cv_calibration:\n",
    "    driver: local\n",
    "  cv_results:\n",
    "    driver: local\n",
    "  cv_db_data:\n",
    "    driver: local\n",
    "  cv_storage_data:\n",
    "    driver: local\n",
    "  jupyter_notebooks:\n",
    "    driver: local\n",
    "\"\"\"\n",
    "\n",
    "# Create CV database initialization script\n",
    "cv_db_init = \"\"\"\n",
    "-- Computer Vision Database Schema\n",
    "CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n",
    "\n",
    "-- Camera calibration data table\n",
    "CREATE TABLE camera_calibrations (\n",
    "    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n",
    "    camera_name VARCHAR(255) NOT NULL,\n",
    "    calibration_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    camera_matrix JSONB NOT NULL,\n",
    "    distortion_coefficients JSONB NOT NULL,\n",
    "    image_width INTEGER NOT NULL,\n",
    "    image_height INTEGER NOT NULL,\n",
    "    calibration_error FLOAT,\n",
    "    calibration_method VARCHAR(50), -- 'eight_point', 'tsai', 'opencv'\n",
    "    notes TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Stereo calibration data table\n",
    "CREATE TABLE stereo_calibrations (\n",
    "    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n",
    "    stereo_pair_name VARCHAR(255) NOT NULL,\n",
    "    left_camera_id UUID REFERENCES camera_calibrations(id),\n",
    "    right_camera_id UUID REFERENCES camera_calibrations(id),\n",
    "    rotation_matrix JSONB NOT NULL,\n",
    "    translation_vector JSONB NOT NULL,\n",
    "    essential_matrix JSONB NOT NULL,\n",
    "    fundamental_matrix JSONB NOT NULL,\n",
    "    baseline_mm FLOAT,\n",
    "    calibration_error FLOAT,\n",
    "    rectification_maps_path TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Calibration images metadata\n",
    "CREATE TABLE calibration_images (\n",
    "    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n",
    "    calibration_id UUID REFERENCES camera_calibrations(id),\n",
    "    image_path TEXT NOT NULL,\n",
    "    corners_detected INTEGER,\n",
    "    corner_coordinates JSONB,\n",
    "    image_quality_score FLOAT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Object points for calibration patterns\n",
    "CREATE TABLE calibration_patterns (\n",
    "    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n",
    "    pattern_name VARCHAR(255) NOT NULL,\n",
    "    pattern_type VARCHAR(50), -- 'chessboard', 'circles', 'asymmetric_circles'\n",
    "    rows INTEGER NOT NULL,\n",
    "    columns INTEGER NOT NULL,\n",
    "    square_size_mm FLOAT,\n",
    "    circle_size_mm FLOAT,\n",
    "    pattern_description TEXT,\n",
    "    object_points JSONB NOT NULL,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "-- Create indexes for performance\n",
    "CREATE INDEX idx_camera_calibrations_name ON camera_calibrations(camera_name);\n",
    "CREATE INDEX idx_stereo_calibrations_pair ON stereo_calibrations(stereo_pair_name);\n",
    "CREATE INDEX idx_calibration_images_calib_id ON calibration_images(calibration_id);\n",
    "CREATE INDEX idx_calibration_date ON camera_calibrations(calibration_date);\n",
    "\n",
    "-- Insert default calibration patterns\n",
    "INSERT INTO calibration_patterns (pattern_name, pattern_type, rows, columns, square_size_mm, object_points) VALUES\n",
    "('Standard_Chessboard_9x6', 'chessboard', 9, 6, 25.0, '[]'),\n",
    "('Large_Chessboard_11x8', 'chessboard', 11, 8, 30.0, '[]'),\n",
    "('Circle_Grid_4x11', 'circles', 4, 11, 15.0, '[]');\n",
    "\n",
    "COMMENT ON TABLE camera_calibrations IS 'Stores individual camera calibration parameters';\n",
    "COMMENT ON TABLE stereo_calibrations IS 'Stores stereo camera system calibration data';\n",
    "COMMENT ON TABLE calibration_images IS 'Metadata for calibration images and detected corners';\n",
    "COMMENT ON TABLE calibration_patterns IS 'Standard calibration patterns and their object points';\n",
    "\"\"\"\n",
    "\n",
    "# Write the configuration files\n",
    "os.makedirs('docker/cv', exist_ok=True)\n",
    "\n",
    "with open('docker/cv/docker-compose.cv.yml', 'w') as f:\n",
    "    f.write(cv_compose_config.strip())\n",
    "\n",
    "with open('docker/cv/init-cv-db.sql', 'w') as f:\n",
    "    f.write(cv_db_init.strip())\n",
    "\n",
    "print(\"âœ… Created computer vision Docker Compose configuration:\")\n",
    "print(\"   - docker/cv/docker-compose.cv.yml\")\n",
    "print(\"   - docker/cv/init-cv-db.sql\")\n",
    "print(\"\")\n",
    "print(\"ðŸŽ¯ Computer vision services include:\")\n",
    "print(\"   - CV development container with Jupyter Lab\")\n",
    "print(\"   - Camera calibration microservice\")\n",
    "print(\"   - Stereo vision processing service\")\n",
    "print(\"   - PostgreSQL database for calibration data\")\n",
    "print(\"   - MinIO object storage for datasets/models\")\n",
    "print(\"   - Camera device access for live calibration\")\n",
    "print(\"   - Persistent volumes for data management\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71672a56",
   "metadata": {},
   "source": [
    "## 10. Universal Development Automation\n",
    "\n",
    "### Makefile and Script Automation\n",
    "\n",
    "Creating universal automation scripts that work across all development environments and provide consistent commands for any project type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Universal Makefile for all development tasks\n",
    "universal_makefile = \"\"\"\n",
    "# Universal Docker Development Environment Makefile\n",
    "# Works with any project type: backend, frontend, computer vision, etc.\n",
    "\n",
    ".PHONY: help dev-start dev-stop dev-reset build test lint deploy clean logs health status\n",
    "\n",
    "# Default target\n",
    "help: ## Show this help message\n",
    "\t@echo \"Universal Docker Development Environment\"\n",
    "\t@echo \"=======================================\"\n",
    "\t@echo \"\"\n",
    "\t@echo \"Available commands:\"\n",
    "\t@awk 'BEGIN {FS = \":.*?## \"} /^[a-zA-Z_-]+:.*?## / {printf \"  \\\\033[36m%-20s\\\\033[0m %s\\\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n",
    "\n",
    "# Development Environment Management\n",
    "dev-start: ## Start all development containers\n",
    "\t@echo \"ðŸš€ Starting universal development environment...\"\n",
    "\t@docker-compose up -d\n",
    "\t@$(MAKE) health\n",
    "\t@echo \"âœ… Development environment ready!\"\n",
    "\t@echo \"ðŸ“‹ Access points:\"\n",
    "\t@echo \"   - Backend API: http://localhost:3000\"\n",
    "\t@echo \"   - Frontend: http://localhost:3001\"\n",
    "\t@echo \"   - Jupyter Lab: http://localhost:8888\"\n",
    "\t@echo \"   - Database Admin: http://localhost:5050\"\n",
    "\t@echo \"   - Monitoring: http://localhost:9090\"\n",
    "\n",
    "dev-start-cv: ## Start computer vision development environment\n",
    "\t@echo \"ðŸ“¸ Starting computer vision development environment...\"\n",
    "\t@docker-compose -f docker-compose.yml -f docker/cv/docker-compose.cv.yml up -d\n",
    "\t@echo \"âœ… Computer vision environment ready!\"\n",
    "\t@echo \"ðŸ“‹ CV Access points:\"\n",
    "\t@echo \"   - Jupyter Lab: http://localhost:8888\"\n",
    "\t@echo \"   - Calibration API: http://localhost:5001\"\n",
    "\t@echo \"   - Stereo Processing: http://localhost:5002\"\n",
    "\t@echo \"   - CV Database: localhost:5433\"\n",
    "\n",
    "dev-stop: ## Stop all development containers\n",
    "\t@echo \"ðŸ›‘ Stopping development environment...\"\n",
    "\t@docker-compose down\n",
    "\t@docker-compose -f docker/cv/docker-compose.cv.yml down 2>/dev/null || true\n",
    "\t@echo \"âœ… Development environment stopped\"\n",
    "\n",
    "dev-reset: ## Reset development environment (removes volumes)\n",
    "\t@echo \"ðŸ”„ Resetting development environment...\"\n",
    "\t@read -p \"This will delete all data. Continue? [y/N] \" -n 1 -r; \\\\\n",
    "\tif [[ $$REPLY =~ ^[Yy]$$ ]]; then \\\\\n",
    "\t\tdocker-compose down -v; \\\\\n",
    "\t\tdocker-compose -f docker/cv/docker-compose.cv.yml down -v 2>/dev/null || true; \\\\\n",
    "\t\tdocker system prune -f; \\\\\n",
    "\t\techo \"âœ… Environment reset complete\"; \\\\\n",
    "\telse \\\\\n",
    "\t\techo \"âŒ Reset cancelled\"; \\\\\n",
    "\tfi\n",
    "\n",
    "# Container Management\n",
    "build: ## Build all development containers\n",
    "\t@echo \"ðŸ”¨ Building development containers...\"\n",
    "\t@docker-compose build --parallel\n",
    "\t@docker-compose -f docker/cv/docker-compose.cv.yml build --parallel 2>/dev/null || true\n",
    "\t@echo \"âœ… All containers built successfully\"\n",
    "\n",
    "rebuild: ## Rebuild containers without cache\n",
    "\t@echo \"ðŸ”¨ Rebuilding containers from scratch...\"\n",
    "\t@docker-compose build --no-cache --parallel\n",
    "\t@docker-compose -f docker/cv/docker-compose.cv.yml build --no-cache --parallel 2>/dev/null || true\n",
    "\t@echo \"âœ… All containers rebuilt successfully\"\n",
    "\n",
    "# Code Quality and Testing\n",
    "test: ## Run all tests in containers\n",
    "\t@echo \"ðŸ§ª Running comprehensive test suite...\"\n",
    "\t@docker-compose exec backend-dev npm test 2>/dev/null || true\n",
    "\t@docker-compose exec backend-dev python -m pytest 2>/dev/null || true\n",
    "\t@docker-compose exec frontend-dev npm test 2>/dev/null || true\n",
    "\t@docker-compose exec dev-tools /scripts/quality-check.sh 2>/dev/null || true\n",
    "\t@echo \"âœ… Test suite completed\"\n",
    "\n",
    "test-cv: ## Run computer vision specific tests\n",
    "\t@echo \"ðŸ“¸ Running computer vision tests...\"\n",
    "\t@docker-compose exec cv-dev python -m pytest /workspace/tests/ 2>/dev/null || true\n",
    "\t@docker-compose exec cv-dev python /workspace/scripts/calibration_tests.py 2>/dev/null || true\n",
    "\t@echo \"âœ… CV tests completed\"\n",
    "\n",
    "lint: ## Run code quality checks\n",
    "\t@echo \"ðŸ” Running code quality analysis...\"\n",
    "\t@docker-compose exec dev-tools /scripts/quality-check.sh\n",
    "\t@echo \"âœ… Code quality check completed\"\n",
    "\n",
    "format: ## Format code using all formatters\n",
    "\t@echo \"âœ¨ Formatting code...\"\n",
    "\t@docker-compose exec dev-tools black /workspace --exclude=venv 2>/dev/null || true\n",
    "\t@docker-compose exec dev-tools prettier --write /workspace 2>/dev/null || true\n",
    "\t@docker-compose exec dev-tools gofmt -w /workspace 2>/dev/null || true\n",
    "\t@echo \"âœ… Code formatting completed\"\n",
    "\n",
    "# Database Operations\n",
    "db-reset: ## Reset development database\n",
    "\t@echo \"ðŸ—„ï¸ Resetting development database...\"\n",
    "\t@docker-compose exec postgres-dev psql -U devuser -d devdb -c \"DROP SCHEMA public CASCADE; CREATE SCHEMA public;\"\n",
    "\t@echo \"âœ… Database reset completed\"\n",
    "\n",
    "db-migrate: ## Run database migrations\n",
    "\t@echo \"ðŸ”„ Running database migrations...\"\n",
    "\t@docker-compose exec backend-dev npm run migrate 2>/dev/null || true\n",
    "\t@docker-compose exec backend-dev python manage.py migrate 2>/dev/null || true\n",
    "\t@echo \"âœ… Migrations completed\"\n",
    "\n",
    "db-seed: ## Seed database with development data\n",
    "\t@echo \"ðŸŒ± Seeding database with development data...\"\n",
    "\t@docker-compose exec backend-dev npm run seed 2>/dev/null || true\n",
    "\t@docker-compose exec backend-dev python manage.py loaddata fixtures/dev_data.json 2>/dev/null || true\n",
    "\t@echo \"âœ… Database seeded\"\n",
    "\n",
    "# Monitoring and Debugging\n",
    "logs: ## Show logs from all containers\n",
    "\t@echo \"ðŸ“‹ Showing container logs...\"\n",
    "\t@docker-compose logs -f --tail=100\n",
    "\n",
    "logs-cv: ## Show computer vision container logs\n",
    "\t@echo \"ðŸ“‹ Showing CV container logs...\"\n",
    "\t@docker-compose -f docker/cv/docker-compose.cv.yml logs -f --tail=100\n",
    "\n",
    "health: ## Check health of all services\n",
    "\t@echo \"ðŸ¥ Checking service health...\"\n",
    "\t@docker-compose ps\n",
    "\t@echo \"\"\n",
    "\t@echo \"Health status:\"\n",
    "\t@docker-compose exec postgres-dev pg_isready -U devuser 2>/dev/null && echo \"âœ… PostgreSQL: healthy\" || echo \"âŒ PostgreSQL: unhealthy\"\n",
    "\t@docker-compose exec redis-dev redis-cli ping 2>/dev/null | grep -q PONG && echo \"âœ… Redis: healthy\" || echo \"âŒ Redis: unhealthy\"\n",
    "\t@curl -sf http://localhost:3000/health >/dev/null 2>&1 && echo \"âœ… Backend API: healthy\" || echo \"âŒ Backend API: unhealthy\"\n",
    "\t@curl -sf http://localhost:3001 >/dev/null 2>&1 && echo \"âœ… Frontend: healthy\" || echo \"âŒ Frontend: unhealthy\"\n",
    "\n",
    "status: ## Show detailed status of development environment\n",
    "\t@echo \"ðŸ“Š Development Environment Status\"\n",
    "\t@echo \"=================================\"\n",
    "\t@echo \"\"\n",
    "\t@echo \"ðŸ³ Container Status:\"\n",
    "\t@docker-compose ps --format \"table {{.Name}}\\\\t{{.Status}}\\\\t{{.Ports}}\"\n",
    "\t@echo \"\"\n",
    "\t@echo \"ðŸ’¾ Volume Usage:\"\n",
    "\t@docker volume ls --format \"table {{.Name}}\\\\t{{.Size}}\" | grep -E \"(postgres_data|redis_data|node_modules)\"\n",
    "\t@echo \"\"\n",
    "\t@echo \"ðŸŒ Network Status:\"\n",
    "\t@docker network ls --format \"table {{.Name}}\\\\t{{.Driver}}\" | grep dev-network\n",
    "\n",
    "# Environment Setup\n",
    "setup: ## Initial setup of development environment\n",
    "\t@echo \"âš™ï¸ Setting up universal development environment...\"\n",
    "\t@chmod +x scripts/dev-setup.sh\n",
    "\t@./scripts/dev-setup.sh\n",
    "\t@$(MAKE) build\n",
    "\t@$(MAKE) dev-start\n",
    "\t@echo \"ðŸŽ‰ Setup completed! Environment ready for development.\"\n",
    "\n",
    "setup-cv: ## Setup computer vision development environment\n",
    "\t@echo \"ðŸ“¸ Setting up computer vision development environment...\"\n",
    "\t@chmod +x scripts/cv-setup.sh\n",
    "\t@./scripts/cv-setup.sh\n",
    "\t@$(MAKE) build\n",
    "\t@$(MAKE) dev-start-cv\n",
    "\t@echo \"ðŸŽ‰ CV environment ready!\"\n",
    "\n",
    "# Deployment\n",
    "deploy-staging: ## Deploy to staging environment\n",
    "\t@echo \"ðŸš€ Deploying to staging...\"\n",
    "\t@docker-compose -f docker-compose.staging.yml up -d\n",
    "\t@echo \"âœ… Staging deployment completed\"\n",
    "\n",
    "deploy-prod: ## Deploy to production environment\n",
    "\t@echo \"ðŸš€ Deploying to production...\"\n",
    "\t@read -p \"Deploy to production? [y/N] \" -n 1 -r; \\\\\n",
    "\tif [[ $$REPLY =~ ^[Yy]$$ ]]; then \\\\\n",
    "\t\tdocker-compose -f docker-compose.prod.yml up -d; \\\\\n",
    "\t\techo \"âœ… Production deployment completed\"; \\\\\n",
    "\telse \\\\\n",
    "\t\techo \"âŒ Production deployment cancelled\"; \\\\\n",
    "\tfi\n",
    "\n",
    "# Cleanup\n",
    "clean: ## Clean up unused Docker resources\n",
    "\t@echo \"ðŸ§¹ Cleaning up Docker resources...\"\n",
    "\t@docker system prune -f\n",
    "\t@docker volume prune -f\n",
    "\t@echo \"âœ… Cleanup completed\"\n",
    "\n",
    "clean-all: ## Clean up everything including volumes\n",
    "\t@echo \"ðŸ§¹ Deep cleaning Docker resources...\"\n",
    "\t@read -p \"This will remove ALL unused Docker resources. Continue? [y/N] \" -n 1 -r; \\\\\n",
    "\tif [[ $$REPLY =~ ^[Yy]$$ ]]; then \\\\\n",
    "\t\tdocker system prune -a -f --volumes; \\\\\n",
    "\t\techo \"âœ… Deep cleanup completed\"; \\\\\n",
    "\telse \\\\\n",
    "\t\techo \"âŒ Deep cleanup cancelled\"; \\\\\n",
    "\tfi\n",
    "\n",
    "# Development Tools\n",
    "shell: ## Open shell in backend development container\n",
    "\t@docker-compose exec backend-dev bash\n",
    "\n",
    "shell-cv: ## Open shell in computer vision container\n",
    "\t@docker-compose exec cv-dev bash\n",
    "\n",
    "shell-db: ## Open database shell\n",
    "\t@docker-compose exec postgres-dev psql -U devuser -d devdb\n",
    "\n",
    "backup-db: ## Backup development database\n",
    "\t@echo \"ðŸ’¾ Creating database backup...\"\n",
    "\t@mkdir -p backups\n",
    "\t@docker-compose exec postgres-dev pg_dump -U devuser -d devdb > backups/dev_backup_$(shell date +%Y%m%d_%H%M%S).sql\n",
    "\t@echo \"âœ… Database backup created in backups/\"\n",
    "\n",
    "restore-db: ## Restore database from backup (requires BACKUP_FILE variable)\n",
    "\t@echo \"ðŸ”„ Restoring database from backup...\"\n",
    "\t@if [ -z \"$(BACKUP_FILE)\" ]; then echo \"âŒ Please specify BACKUP_FILE=path/to/backup.sql\"; exit 1; fi\n",
    "\t@docker-compose exec -T postgres-dev psql -U devuser -d devdb < $(BACKUP_FILE)\n",
    "\t@echo \"âœ… Database restored from $(BACKUP_FILE)\"\n",
    "\n",
    "# Camera Calibration Specific Commands\n",
    "calibrate-camera: ## Run camera calibration workflow\n",
    "\t@echo \"ðŸ“¸ Starting camera calibration...\"\n",
    "\t@docker-compose exec cv-dev python /workspace/scripts/calibration_workflow.py\n",
    "\t@echo \"âœ… Camera calibration completed\"\n",
    "\n",
    "stereo-calibrate: ## Run stereo camera calibration\n",
    "\t@echo \"ðŸ“¹ Starting stereo calibration...\"\n",
    "\t@docker-compose exec cv-dev python /workspace/scripts/stereo_calibration_workflow.py\n",
    "\t@echo \"âœ… Stereo calibration completed\"\n",
    "\n",
    "process-stereo: ## Process stereo image pairs\n",
    "\t@echo \"ðŸ” Processing stereo images...\"\n",
    "\t@docker-compose exec cv-dev python /workspace/scripts/stereo_processing.py\n",
    "\t@echo \"âœ… Stereo processing completed\"\n",
    "\"\"\"\n",
    "\n",
    "# Create universal setup script\n",
    "setup_script = \"\"\"#!/bin/bash\n",
    "# Universal Development Environment Setup Script\n",
    "\n",
    "set -e\n",
    "\n",
    "echo \"ðŸš€ Universal Docker Development Environment Setup\"\n",
    "echo \"================================================\"\n",
    "\n",
    "# Check prerequisites\n",
    "echo \"ðŸ” Checking prerequisites...\"\n",
    "\n",
    "# Check Docker\n",
    "if ! command -v docker &> /dev/null; then\n",
    "    echo \"âŒ Docker is not installed. Please install Docker first.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Check Docker Compose\n",
    "if ! command -v docker-compose &> /dev/null; then\n",
    "    echo \"âŒ Docker Compose is not installed. Please install Docker Compose first.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "echo \"âœ… Docker and Docker Compose found\"\n",
    "\n",
    "# Create necessary directories\n",
    "echo \"ðŸ“ Creating directory structure...\"\n",
    "mkdir -p {logs,data,config,backups,scripts}\n",
    "mkdir -p {docker/development,docker/production,docker/tools,docker/cv}\n",
    "mkdir -p {.devcontainer,data/dev,logs/dev}\n",
    "\n",
    "# Create environment files\n",
    "echo \"âš™ï¸ Setting up environment configuration...\"\n",
    "\n",
    "# Development environment file\n",
    "cat > .env.development << EOF\n",
    "NODE_ENV=development\n",
    "PYTHON_ENV=development\n",
    "DATABASE_URL=postgresql://devuser:devpass@postgres-dev:5432/devdb\n",
    "REDIS_URL=redis://redis-dev:6379\n",
    "MINIO_ROOT_USER=minioadmin\n",
    "MINIO_ROOT_PASSWORD=minioadmin123\n",
    "\n",
    "# Computer Vision specific\n",
    "OPENCV_VERSION=4.8.0\n",
    "CALIBRATION_DATA_PATH=/workspace/calibration_data\n",
    "PROCESSING_THREADS=4\n",
    "STEREO_ALGORITHM=SGBM\n",
    "\n",
    "# Jupyter configuration\n",
    "JUPYTER_ENABLE_LAB=yes\n",
    "JUPYTER_TOKEN=dev-token-123\n",
    "EOF\n",
    "\n",
    "# Production environment template\n",
    "cat > .env.production.template << EOF\n",
    "NODE_ENV=production\n",
    "DATABASE_URL=postgresql://user:password@prod-db:5432/proddb\n",
    "REDIS_URL=redis://prod-redis:6379\n",
    "SECRET_KEY=your-secret-key-here\n",
    "EOF\n",
    "\n",
    "# Create Git hooks directory\n",
    "mkdir -p .git/hooks\n",
    "\n",
    "# Setup pre-commit hook\n",
    "cat > .git/hooks/pre-commit << EOF\n",
    "#!/bin/bash\n",
    "echo \"ðŸ” Running pre-commit checks...\"\n",
    "make lint\n",
    "EOF\n",
    "\n",
    "chmod +x .git/hooks/pre-commit\n",
    "\n",
    "# Create initial configuration files\n",
    "echo \"ðŸ“ Creating configuration files...\"\n",
    "\n",
    "# Create .dockerignore\n",
    "cat > .dockerignore << EOF\n",
    ".git\n",
    ".gitignore\n",
    "README.md\n",
    "Dockerfile\n",
    ".dockerignore\n",
    "node_modules\n",
    "npm-debug.log\n",
    "coverage\n",
    ".nyc_output\n",
    ".cache\n",
    "logs\n",
    "*.log\n",
    ".DS_Store\n",
    ".vscode\n",
    ".idea\n",
    "__pycache__\n",
    "*.pyc\n",
    ".pytest_cache\n",
    ".coverage\n",
    "EOF\n",
    "\n",
    "# Create health check script\n",
    "cat > scripts/health-check.sh << EOF\n",
    "#!/bin/bash\n",
    "# Universal health check script\n",
    "\n",
    "echo \"ðŸ¥ Running health checks...\"\n",
    "\n",
    "# Check database\n",
    "if docker-compose exec postgres-dev pg_isready -U devuser &> /dev/null; then\n",
    "    echo \"âœ… Database: healthy\"\n",
    "else\n",
    "    echo \"âŒ Database: unhealthy\"\n",
    "fi\n",
    "\n",
    "# Check Redis\n",
    "if docker-compose exec redis-dev redis-cli ping | grep -q PONG; then\n",
    "    echo \"âœ… Redis: healthy\"\n",
    "else\n",
    "    echo \"âŒ Redis: unhealthy\"\n",
    "fi\n",
    "\n",
    "# Check API endpoints\n",
    "if curl -sf http://localhost:3000/health &> /dev/null; then\n",
    "    echo \"âœ… Backend API: healthy\"\n",
    "else\n",
    "    echo \"âŒ Backend API: unhealthy\"\n",
    "fi\n",
    "\n",
    "echo \"ðŸ¥ Health check completed\"\n",
    "EOF\n",
    "\n",
    "chmod +x scripts/health-check.sh\n",
    "\n",
    "echo \"âœ… Universal development environment setup completed!\"\n",
    "echo \"\"\n",
    "echo \"ðŸ“‹ Next steps:\"\n",
    "echo \"1. Run 'make build' to build all containers\"\n",
    "echo \"2. Run 'make dev-start' to start the development environment\"\n",
    "echo \"3. Run 'make help' to see all available commands\"\n",
    "echo \"\"\n",
    "echo \"ðŸŽ‰ Happy coding!\"\n",
    "\"\"\"\n",
    "\n",
    "# Write Makefile and setup script\n",
    "with open('Makefile', 'w') as f:\n",
    "    f.write(universal_makefile.strip())\n",
    "\n",
    "with open('scripts/dev-setup.sh', 'w') as f:\n",
    "    f.write(setup_script.strip())\n",
    "\n",
    "# Make setup script executable\n",
    "import stat\n",
    "setup_path = 'scripts/dev-setup.sh'\n",
    "current_permissions = os.stat(setup_path).st_mode\n",
    "os.chmod(setup_path, current_permissions | stat.S_IEXEC)\n",
    "\n",
    "print(\"âœ… Created universal automation system:\")\n",
    "print(\"   - Makefile (universal development commands)\")\n",
    "print(\"   - scripts/dev-setup.sh (environment setup)\")\n",
    "print(\"\")\n",
    "print(\"ðŸŽ¯ Available make commands:\")\n",
    "print(\"   - make setup: Complete environment setup\")\n",
    "print(\"   - make dev-start: Start development environment\")\n",
    "print(\"   - make dev-start-cv: Start computer vision environment\")\n",
    "print(\"   - make test: Run all tests\")\n",
    "print(\"   - make lint: Code quality checks\")\n",
    "print(\"   - make calibrate-camera: Camera calibration workflow\")\n",
    "print(\"   - make stereo-calibrate: Stereo calibration\")\n",
    "print(\"   - make logs: View container logs\")\n",
    "print(\"   - make health: Check service health\")\n",
    "print(\"   - make clean: Clean up Docker resources\")\n",
    "print(\"\")\n",
    "print(\"âš¡ Quick start: Run 'make setup' to begin!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613d6ae",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Universal Docker Development Strategy Complete!\n",
    "\n",
    "### Summary of Implementation\n",
    "\n",
    "You now have a **complete containerized development strategy** that eliminates dependency conflicts and provides consistent environments across any machine. This implementation specifically addresses your computer vision project needs while being universally applicable to any development scenario.\n",
    "\n",
    "### ðŸ”‘ Key Components Delivered\n",
    "\n",
    "#### 1. **Core Development Containers**\n",
    "- **Backend Development**: Multi-language support (Python, Node.js, Go, Java, Rust)\n",
    "- **Frontend Development**: Modern frameworks with hot reload (React, Vue, Angular)\n",
    "- **Computer Vision**: Specialized CV environment with OpenCV, calibration algorithms\n",
    "- **Development Tools**: Code quality, testing, security scanning, CI/CD utilities\n",
    "\n",
    "#### 2. **Camera Calibration Implementation**\n",
    "- **Eight-Point Algorithm**: Fundamental matrix estimation with SVD\n",
    "- **Tsai's Two-Stage Calibration**: RAC constraint-based calibration\n",
    "- **Stereo Calibration**: Combined approach for robust stereo systems\n",
    "- **Database Schema**: PostgreSQL storage for calibration data and metadata\n",
    "\n",
    "#### 3. **Infrastructure Services**\n",
    "- **Multiple Databases**: PostgreSQL, MySQL, MongoDB, Redis, Elasticsearch\n",
    "- **Object Storage**: MinIO for datasets, models, and large files\n",
    "- **Message Queues**: RabbitMQ for microservice communication\n",
    "- **Monitoring**: Prometheus and health checks\n",
    "\n",
    "#### 4. **IDE Integration**\n",
    "- **VS Code Dev Containers**: Pre-configured with 40+ extensions\n",
    "- **Remote Development**: GitHub Codespaces and cloud-ready setup\n",
    "- **Debugging Support**: Multi-language debugging and profiling\n",
    "- **Port Forwarding**: Automatic service discovery and access\n",
    "\n",
    "#### 5. **Production Optimization**\n",
    "- **Multi-Stage Builds**: Minimal production images\n",
    "- **Security Hardening**: Non-root users, distroless base images\n",
    "- **Health Checks**: Comprehensive monitoring and alerting\n",
    "- **Container Orchestration**: Kubernetes and Docker Swarm ready\n",
    "\n",
    "### ðŸš€ Immediate Benefits\n",
    "\n",
    "#### âœ… **\"Works on My Machine\" Eliminated**\n",
    "Every developer gets identical environments regardless of their host OS (Windows, Mac, Linux)\n",
    "\n",
    "#### âœ… **Zero Local Dependencies** \n",
    "No need to install Python, Node.js, databases, or any development tools locally\n",
    "\n",
    "#### âœ… **Team Consistency**\n",
    "Standardized development environments across your entire team\n",
    "\n",
    "#### âœ… **Easy Onboarding**\n",
    "New developers productive in minutes with `make setup`\n",
    "\n",
    "#### âœ… **Production Parity**\n",
    "Development environments mirror production for reliable deployments\n",
    "\n",
    "#### âœ… **Specialized CV Environment**\n",
    "Ready-to-use computer vision development with calibration algorithms implemented\n",
    "\n",
    "### ðŸ› ï¸ Quick Start Instructions\n",
    "\n",
    "1. **Run the setup command:**\n",
    "   ```bash\n",
    "   make setup\n",
    "   ```\n",
    "\n",
    "2. **Start computer vision environment:**\n",
    "   ```bash\n",
    "   make dev-start-cv\n",
    "   ```\n",
    "\n",
    "3. **Access development services:**\n",
    "   - Jupyter Lab: http://localhost:8888\n",
    "   - Calibration API: http://localhost:5001\n",
    "   - Stereo Processing: http://localhost:5002\n",
    "   - Database Admin: http://localhost:5050\n",
    "\n",
    "4. **Run camera calibration:**\n",
    "   ```bash\n",
    "   make calibrate-camera\n",
    "   ```\n",
    "\n",
    "### ðŸ“¸ Computer Vision Specific Features\n",
    "\n",
    "Your implementation includes production-ready camera calibration algorithms:\n",
    "\n",
    "- **Fundamental Matrix Estimation** using the eight-point algorithm\n",
    "- **Essential Matrix Decomposition** for pose estimation  \n",
    "- **Radial Alignment Constraint** implementation (Tsai method)\n",
    "- **Stereo Rectification** for disparity computation\n",
    "- **Robust Pose Selection** with depth validation\n",
    "- **Database Storage** for calibration parameters and metadata\n",
    "\n",
    "### ðŸ”„ Development Workflow\n",
    "\n",
    "1. **Code in VS Code** with full IntelliSense and debugging\n",
    "2. **Live Reload** for instant feedback during development\n",
    "3. **Automated Testing** with `make test` and `make test-cv`\n",
    "4. **Code Quality** enforcement with `make lint` and `make format`\n",
    "5. **Camera Calibration** workflows with dedicated commands\n",
    "6. **Production Deployment** with optimized containers\n",
    "\n",
    "This universal strategy scales from single-developer projects to large teams and from simple web apps to complex computer vision systems. Your stereo vision project now has a professional, containerized development environment that ensures consistency and eliminates environment-related issues!\n",
    "\n",
    "### ðŸŽ¯ Next Steps\n",
    "\n",
    "1. **Customize** the containers for your specific project needs\n",
    "2. **Add** project-specific calibration patterns and test data\n",
    "3. **Integrate** with your existing CI/CD pipelines\n",
    "4. **Scale** the environment for your team's requirements\n",
    "5. **Deploy** to production using the optimized containers\n",
    "\n",
    "**Happy coding with your new universal development environment!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
